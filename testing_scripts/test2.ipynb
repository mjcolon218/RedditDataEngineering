{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from requests.auth import HTTPBasicAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'secret' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m username \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmjcolon218\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m password\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBronxnyc86!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m auth \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mHTTPBasicAuth(client_id,\u001b[43msecret\u001b[49m)\n\u001b[0;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrant_type\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m\"\u001b[39m:username,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m:password\n\u001b[0;32m     18\u001b[0m }\n\u001b[0;32m     20\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest-app by u/mjcolon218\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'secret' is not defined"
     ]
    }
   ],
   "source": [
    "import requests.auth\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import praw\n",
    "from praw import Reddit\n",
    "client_id = \"41k6oW3UThpKVf6xD5O_Mg\"\n",
    "client_secret = \"kHZiEFT2TaDqw3VUJQjHtP4SruQtDA\"\n",
    "username =\"mjcolon218\"\n",
    "password=\"Bronxnyc86!\"\n",
    "auth = requests.auth.HTTPBasicAuth(client_id,secret)\n",
    "data = {\n",
    "    \"grant_type\":\"password\",\n",
    "    \"username\":username,\n",
    "    \"password\":password\n",
    "}\n",
    "\n",
    "headers = {\"User-Agent\":\"test-app by u/mjcolon218\"}\n",
    "\n",
    "r= requests.post(\"https://www.reddit.com/api/v1/access_token\",auth=auth,data=data,headers=headers)\n",
    "rjson = r.json()\n",
    "print(rjson)\n",
    "r.raise_for_status()\n",
    "access_token = rjson['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_reddit(client_id, client_secret, user_agent) -> Reddit:\n",
    "    try:\n",
    "        reddit = praw.Reddit(client_id=client_id,\n",
    "                             client_secret=client_secret,\n",
    "                             user_agent=user_agent,\n",
    "                             refresh_token = access_token,\n",
    "                             username=username,\n",
    "                             password=password)\n",
    "        print(\"connected to reddit!\")\n",
    "        print(reddit.user.me())\n",
    "        return reddit\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected to reddit!\n",
      "mjcolon218\n"
     ]
    }
   ],
   "source": [
    "instance = connect_reddit(client_id=client_id,client_secret=client_secret,user_agent=\"Moe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = instance.subreddit(\"machinelearning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = subreddit.top(limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<praw.models.listing.generator.ListingGenerator at 0x1caf6cbac40>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_reddit': <praw.reddit.Reddit object at 0x000001CAF6CBA5B0>, '_exhausted': False, '_listing': None, '_list_index': None, 'limit': 25, 'params': {'t': 'all', 'limit': 25}, 'url': 'r/machinelearning/top', 'yielded': 0}\n"
     ]
    }
   ],
   "source": [
    "print(vars(posts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_reddit': <praw.reddit.Reddit at 0x1caf6cba5b0>,\n",
       " '_exhausted': False,\n",
       " '_listing': None,\n",
       " '_list_index': None,\n",
       " 'limit': 25,\n",
       " 'params': {'t': 'all', 'limit': 25},\n",
       " 'url': 'r/machinelearning/top',\n",
       " 'yielded': 0}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJ1c2VyIiwiZXhwIjoxNzE2NzQ2NzAyLjU3OTQzMywiaWF0IjoxNzE2NjYwMzAyLjU3OTQzMywianRpIjoiUDZLc0c5d2Z2dEU0VjZNY29zcnFIVWtpRHQzR2lRIiwiY2lkIjoiNDFrNm9XM1VUaHBLVmY2eEQ1T19NZyIsImxpZCI6InQyX3ZtdHVwNXluIiwiYWlkIjoidDJfdm10dXA1eW4iLCJsY2EiOjE2NzQyNDY1NTMwMDAsInNjcCI6ImVKeUtWdEpTaWdVRUFBRF9fd056QVNjIiwiZmxvIjo5fQ.T5wPVz2H0uAxKPio3-OlQVGrkCqWypXk5-sfSrK9Y3KdcTOb5BW9iEW2ghUETflfsBPbDveQhBWlpoy8lcDdvpEmXPhudEecUsHPHtQu7NpWr2OgQS5gCylCnDPUfObVKOgcSub6Jqn75qGawIyUaA5Q90Yz9GEhUKnbqv5k0fAWggOZURIMJ5CYfKkkxky1xystI7DyyZxNF5v--pfHG16lcpbnLp_xzcgWMVnqKvKlzTrYmxyWlBRFZ5ESCrtpWctM_6fkUvjkQEZNzV9A8dxmAYz0-ixUkMq7iHafSRsExzmcHDxegrjjmdKi665o9zzplc6t0p4vVO8gJxEBpQ'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth = requests.auth.HTTPBasicAuth(client_id,client_secret)\n",
    "data = {'grant_type':'password','username':username,'password':password}\n",
    "headers ={\"User-Agent\": \"test-app by u/mjcolon218\"}\n",
    "r = requests.post(\"https://www.reddit.com/api/v1/access_token\",auth=auth,data=data,headers=headers)\n",
    "reddit_token = r.json()['access_token']\n",
    "reddit_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'Listing',\n",
       " 'data': {'modhash': None,\n",
       "  'dist': 10,\n",
       "  'facets': {},\n",
       "  'after': 't3_12kpq9i',\n",
       "  'geo_filter': '',\n",
       "  'children': [{'kind': 't3',\n",
       "    'data': {'approved_at_utc': None,\n",
       "     'subreddit': 'dataengineering',\n",
       "     'selftext': '',\n",
       "     'author_fullname': 't2_4pzy2btji',\n",
       "     'saved': False,\n",
       "     'mod_reason_title': None,\n",
       "     'gilded': 0,\n",
       "     'clicked': False,\n",
       "     'title': 'How true is this thing of getting “blacklisted” for wrong titles on resumes?',\n",
       "     'link_flair_richtext': [],\n",
       "     'subreddit_name_prefixed': 'r/dataengineering',\n",
       "     'hidden': False,\n",
       "     'pwls': 6,\n",
       "     'link_flair_css_class': '',\n",
       "     'downs': 0,\n",
       "     'thumbnail_height': 140,\n",
       "     'top_awarded_type': None,\n",
       "     'hide_score': False,\n",
       "     'name': 't3_19ab6dx',\n",
       "     'quarantine': False,\n",
       "     'link_flair_text_color': 'light',\n",
       "     'upvote_ratio': 0.89,\n",
       "     'author_flair_background_color': None,\n",
       "     'ups': 52,\n",
       "     'total_awards_received': 0,\n",
       "     'media_embed': {},\n",
       "     'thumbnail_width': 140,\n",
       "     'author_flair_template_id': None,\n",
       "     'is_original_content': False,\n",
       "     'user_reports': [],\n",
       "     'secure_media': None,\n",
       "     'is_reddit_media_domain': True,\n",
       "     'is_meta': False,\n",
       "     'category': None,\n",
       "     'secure_media_embed': {},\n",
       "     'link_flair_text': 'Discussion',\n",
       "     'can_mod_post': False,\n",
       "     'score': 52,\n",
       "     'approved_by': None,\n",
       "     'is_created_from_ads_ui': False,\n",
       "     'author_premium': False,\n",
       "     'thumbnail': 'https://b.thumbs.redditmedia.com/cuA_e70vkmLGdeTFNaHkMsKadak-ldjPOxUPEQohPpw.jpg',\n",
       "     'edited': False,\n",
       "     'author_flair_css_class': None,\n",
       "     'author_flair_richtext': [],\n",
       "     'gildings': {},\n",
       "     'post_hint': 'image',\n",
       "     'content_categories': None,\n",
       "     'is_self': False,\n",
       "     'subreddit_type': 'public',\n",
       "     'created': 1705640646.0,\n",
       "     'link_flair_type': 'text',\n",
       "     'wls': 6,\n",
       "     'removed_by_category': None,\n",
       "     'banned_by': None,\n",
       "     'author_flair_type': 'text',\n",
       "     'domain': 'i.redd.it',\n",
       "     'allow_live_comments': False,\n",
       "     'selftext_html': None,\n",
       "     'likes': None,\n",
       "     'suggested_sort': None,\n",
       "     'banned_at_utc': None,\n",
       "     'url_overridden_by_dest': 'https://i.redd.it/h51r0yfcxbdc1.jpeg',\n",
       "     'view_count': None,\n",
       "     'archived': False,\n",
       "     'no_follow': False,\n",
       "     'is_crosspostable': True,\n",
       "     'pinned': False,\n",
       "     'over_18': False,\n",
       "     'preview': {'images': [{'source': {'url': 'https://preview.redd.it/h51r0yfcxbdc1.jpeg?auto=webp&amp;s=09136918e787fe5de8e922a2e1822c1536a7f9c4',\n",
       "         'width': 750,\n",
       "         'height': 1205},\n",
       "        'resolutions': [{'url': 'https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ced0927fd3b3719458511bc71ff2ccdd641c8a52',\n",
       "          'width': 108,\n",
       "          'height': 173},\n",
       "         {'url': 'https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6a61f119dd5141d0dafd3afde992981047fe7ede',\n",
       "          'width': 216,\n",
       "          'height': 347},\n",
       "         {'url': 'https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f5f55ad22f0cc7f13defcaf55ae9c05f8666af3',\n",
       "          'width': 320,\n",
       "          'height': 514},\n",
       "         {'url': 'https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f2d5ee24b2d9d9d89feea2edd4c800a4603c1d7',\n",
       "          'width': 640,\n",
       "          'height': 1028}],\n",
       "        'variants': {},\n",
       "        'id': 's-z2epHMrUrmxBEW4R-8PpX4yFQk4_gxuS3qaWaPeqk'}],\n",
       "      'enabled': True},\n",
       "     'all_awardings': [],\n",
       "     'awarders': [],\n",
       "     'media_only': False,\n",
       "     'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f',\n",
       "     'can_gild': False,\n",
       "     'spoiler': False,\n",
       "     'locked': False,\n",
       "     'author_flair_text': None,\n",
       "     'treatment_tags': [],\n",
       "     'visited': False,\n",
       "     'removed_by': None,\n",
       "     'mod_note': None,\n",
       "     'distinguished': None,\n",
       "     'subreddit_id': 't5_36en4',\n",
       "     'author_is_blocked': False,\n",
       "     'mod_reason_by': None,\n",
       "     'num_reports': None,\n",
       "     'removal_reason': None,\n",
       "     'link_flair_background_color': '#ff4500',\n",
       "     'id': '19ab6dx',\n",
       "     'is_robot_indexable': True,\n",
       "     'report_reasons': None,\n",
       "     'author': 'gotchabiash',\n",
       "     'discussion_type': None,\n",
       "     'num_comments': 74,\n",
       "     'send_replies': True,\n",
       "     'whitelist_status': 'all_ads',\n",
       "     'contest_mode': False,\n",
       "     'mod_reports': [],\n",
       "     'author_patreon_flair': False,\n",
       "     'author_flair_text_color': None,\n",
       "     'permalink': '/r/dataengineering/comments/19ab6dx/how_true_is_this_thing_of_getting_blacklisted_for/',\n",
       "     'parent_whitelist_status': 'all_ads',\n",
       "     'stickied': False,\n",
       "     'url': 'https://i.redd.it/h51r0yfcxbdc1.jpeg',\n",
       "     'subreddit_subscribers': 185845,\n",
       "     'created_utc': 1705640646.0,\n",
       "     'num_crossposts': 0,\n",
       "     'media': None,\n",
       "     'is_video': False}},\n",
       "   {'kind': 't3',\n",
       "    'data': {'approved_at_utc': None,\n",
       "     'subreddit': 'dataengineering',\n",
       "     'selftext': '',\n",
       "     'author_fullname': 't2_8wc3ja5x',\n",
       "     'saved': False,\n",
       "     'mod_reason_title': None,\n",
       "     'gilded': 0,\n",
       "     'clicked': False,\n",
       "     'title': 'DataEngineering 2021 in one pic',\n",
       "     'link_flair_richtext': [],\n",
       "     'subreddit_name_prefixed': 'r/dataengineering',\n",
       "     'hidden': False,\n",
       "     'pwls': 6,\n",
       "     'link_flair_css_class': '',\n",
       "     'downs': 0,\n",
       "     'thumbnail_height': 140,\n",
       "     'top_awarded_type': None,\n",
       "     'hide_score': False,\n",
       "     'name': 't3_oyju56',\n",
       "     'quarantine': False,\n",
       "     'link_flair_text_color': 'light',\n",
       "     'upvote_ratio': 0.98,\n",
       "     'author_flair_background_color': None,\n",
       "     'ups': 606,\n",
       "     'total_awards_received': 0,\n",
       "     'media_embed': {},\n",
       "     'thumbnail_width': 140,\n",
       "     'author_flair_template_id': None,\n",
       "     'is_original_content': False,\n",
       "     'user_reports': [],\n",
       "     'secure_media': None,\n",
       "     'is_reddit_media_domain': True,\n",
       "     'is_meta': False,\n",
       "     'category': None,\n",
       "     'secure_media_embed': {},\n",
       "     'link_flair_text': 'Career',\n",
       "     'can_mod_post': False,\n",
       "     'score': 606,\n",
       "     'approved_by': None,\n",
       "     'is_created_from_ads_ui': False,\n",
       "     'author_premium': False,\n",
       "     'thumbnail': 'https://b.thumbs.redditmedia.com/n6itUzKOh3oYtUQMsBGOGpwVvlMyUbZeXiCxsPgoovo.jpg',\n",
       "     'edited': False,\n",
       "     'author_flair_css_class': None,\n",
       "     'author_flair_richtext': [],\n",
       "     'gildings': {},\n",
       "     'post_hint': 'image',\n",
       "     'content_categories': None,\n",
       "     'is_self': False,\n",
       "     'subreddit_type': 'public',\n",
       "     'created': 1628174775.0,\n",
       "     'link_flair_type': 'text',\n",
       "     'wls': 6,\n",
       "     'removed_by_category': None,\n",
       "     'banned_by': None,\n",
       "     'author_flair_type': 'text',\n",
       "     'domain': 'i.redd.it',\n",
       "     'allow_live_comments': False,\n",
       "     'selftext_html': None,\n",
       "     'likes': None,\n",
       "     'suggested_sort': None,\n",
       "     'banned_at_utc': None,\n",
       "     'url_overridden_by_dest': 'https://i.redd.it/pdnuk1r0yjf71.jpg',\n",
       "     'view_count': None,\n",
       "     'archived': True,\n",
       "     'no_follow': False,\n",
       "     'is_crosspostable': True,\n",
       "     'pinned': False,\n",
       "     'over_18': False,\n",
       "     'preview': {'images': [{'source': {'url': 'https://preview.redd.it/pdnuk1r0yjf71.jpg?auto=webp&amp;s=1cf198133dfc62e0a5655de7c550d2aea274e21c',\n",
       "         'width': 640,\n",
       "         'height': 2717},\n",
       "        'resolutions': [{'url': 'https://preview.redd.it/pdnuk1r0yjf71.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f82b17d894b091fb746bcc1fae88997c1a19f1b',\n",
       "          'width': 108,\n",
       "          'height': 216},\n",
       "         {'url': 'https://preview.redd.it/pdnuk1r0yjf71.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b5552bae4a5ed105d31fe94db4b15429ab188590',\n",
       "          'width': 216,\n",
       "          'height': 432},\n",
       "         {'url': 'https://preview.redd.it/pdnuk1r0yjf71.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=67d48116db51df511b0e99dc62822d67ec0cea8d',\n",
       "          'width': 320,\n",
       "          'height': 640},\n",
       "         {'url': 'https://preview.redd.it/pdnuk1r0yjf71.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8ec4374de2c25383c3fafc48bf4a5267b32f1e6b',\n",
       "          'width': 640,\n",
       "          'height': 1280}],\n",
       "        'variants': {},\n",
       "        'id': 'L0Na0tk0a9E7q_ragRHveS4dzfkyRO2GaKxFFr57tIM'}],\n",
       "      'enabled': True},\n",
       "     'all_awardings': [],\n",
       "     'awarders': [],\n",
       "     'media_only': False,\n",
       "     'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3',\n",
       "     'can_gild': False,\n",
       "     'spoiler': False,\n",
       "     'locked': False,\n",
       "     'author_flair_text': None,\n",
       "     'treatment_tags': [],\n",
       "     'visited': False,\n",
       "     'removed_by': None,\n",
       "     'mod_note': None,\n",
       "     'distinguished': None,\n",
       "     'subreddit_id': 't5_36en4',\n",
       "     'author_is_blocked': False,\n",
       "     'mod_reason_by': None,\n",
       "     'num_reports': None,\n",
       "     'removal_reason': None,\n",
       "     'link_flair_background_color': '#349e48',\n",
       "     'id': 'oyju56',\n",
       "     'is_robot_indexable': True,\n",
       "     'report_reasons': None,\n",
       "     'author': 'Legitimate-Cry2837',\n",
       "     'discussion_type': None,\n",
       "     'num_comments': 53,\n",
       "     'send_replies': True,\n",
       "     'whitelist_status': 'all_ads',\n",
       "     'contest_mode': False,\n",
       "     'mod_reports': [],\n",
       "     'author_patreon_flair': False,\n",
       "     'author_flair_text_color': None,\n",
       "     'permalink': '/r/dataengineering/comments/oyju56/dataengineering_2021_in_one_pic/',\n",
       "     'parent_whitelist_status': 'all_ads',\n",
       "     'stickied': False,\n",
       "     'url': 'https://i.redd.it/pdnuk1r0yjf71.jpg',\n",
       "     'subreddit_subscribers': 185845,\n",
       "     'created_utc': 1628174775.0,\n",
       "     'num_crossposts': 2,\n",
       "     'media': None,\n",
       "     'is_video': False}},\n",
       "   {'kind': 't3',\n",
       "    'data': {'approved_at_utc': None,\n",
       "     'subreddit': 'dataengineering',\n",
       "     'selftext': 'At works we have an interesting problems which I think is badly solved but I want advices.\\n\\nThe problem is : \\n\\nwe have BIG list of users actions with let say the number of transactions the user done in a specific day, and some other info. (big is potentially billions of lines)\\n\\nthen we want to create list of users with some criterias (let say user that made transactions between data x and y and more than z) and combine them (add/intersect).\\n\\nfor now we store everything in a big Redshift cluster and make SQL query to create export list.  \\nThe cluster is huge (more then 10To / 8 nodes) and this is super slow (queries to create lists but also maintenance tasks). \\n\\nSo I really wonder if any other solutions would be possible. Maybe just storing everything on S3 (or equivalent) and use a big map/reduce (spark?) job would do the job better ?\\n\\nAny hints / ideas appreciated.',\n",
       "     'author_fullname': 't2_lbugjen',\n",
       "     'saved': False,\n",
       "     'mod_reason_title': None,\n",
       "     'gilded': 0,\n",
       "     'clicked': False,\n",
       "     'title': 'DataEngineering Modeling questions',\n",
       "     'link_flair_richtext': [],\n",
       "     'subreddit_name_prefixed': 'r/dataengineering',\n",
       "     'hidden': False,\n",
       "     'pwls': 6,\n",
       "     'link_flair_css_class': '',\n",
       "     'downs': 0,\n",
       "     'thumbnail_height': None,\n",
       "     'top_awarded_type': None,\n",
       "     'hide_score': False,\n",
       "     'name': 't3_1cu0zg1',\n",
       "     'quarantine': False,\n",
       "     'link_flair_text_color': 'light',\n",
       "     'upvote_ratio': 1.0,\n",
       "     'author_flair_background_color': None,\n",
       "     'subreddit_type': 'public',\n",
       "     'ups': 7,\n",
       "     'total_awards_received': 0,\n",
       "     'media_embed': {},\n",
       "     'thumbnail_width': None,\n",
       "     'author_flair_template_id': None,\n",
       "     'is_original_content': False,\n",
       "     'user_reports': [],\n",
       "     'secure_media': None,\n",
       "     'is_reddit_media_domain': False,\n",
       "     'is_meta': False,\n",
       "     'category': None,\n",
       "     'secure_media_embed': {},\n",
       "     'link_flair_text': 'Discussion',\n",
       "     'can_mod_post': False,\n",
       "     'score': 7,\n",
       "     'approved_by': None,\n",
       "     'is_created_from_ads_ui': False,\n",
       "     'author_premium': False,\n",
       "     'thumbnail': 'self',\n",
       "     'edited': False,\n",
       "     'author_flair_css_class': None,\n",
       "     'author_flair_richtext': [],\n",
       "     'gildings': {},\n",
       "     'content_categories': None,\n",
       "     'is_self': True,\n",
       "     'mod_note': None,\n",
       "     'created': 1715937977.0,\n",
       "     'link_flair_type': 'text',\n",
       "     'wls': 6,\n",
       "     'removed_by_category': None,\n",
       "     'banned_by': None,\n",
       "     'author_flair_type': 'text',\n",
       "     'domain': 'self.dataengineering',\n",
       "     'allow_live_comments': False,\n",
       "     'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At works we have an interesting problems which I think is badly solved but I want advices.&lt;/p&gt;\\n\\n&lt;p&gt;The problem is : &lt;/p&gt;\\n\\n&lt;p&gt;we have BIG list of users actions with let say the number of transactions the user done in a specific day, and some other info. (big is potentially billions of lines)&lt;/p&gt;\\n\\n&lt;p&gt;then we want to create list of users with some criterias (let say user that made transactions between data x and y and more than z) and combine them (add/intersect).&lt;/p&gt;\\n\\n&lt;p&gt;for now we store everything in a big Redshift cluster and make SQL query to create export list.&lt;br/&gt;\\nThe cluster is huge (more then 10To / 8 nodes) and this is super slow (queries to create lists but also maintenance tasks). &lt;/p&gt;\\n\\n&lt;p&gt;So I really wonder if any other solutions would be possible. Maybe just storing everything on S3 (or equivalent) and use a big map/reduce (spark?) job would do the job better ?&lt;/p&gt;\\n\\n&lt;p&gt;Any hints / ideas appreciated.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       "     'likes': None,\n",
       "     'suggested_sort': None,\n",
       "     'banned_at_utc': None,\n",
       "     'view_count': None,\n",
       "     'archived': False,\n",
       "     'no_follow': False,\n",
       "     'is_crosspostable': True,\n",
       "     'pinned': False,\n",
       "     'over_18': False,\n",
       "     'all_awardings': [],\n",
       "     'awarders': [],\n",
       "     'media_only': False,\n",
       "     'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f',\n",
       "     'can_gild': False,\n",
       "     'spoiler': False,\n",
       "     'locked': False,\n",
       "     'author_flair_text': None,\n",
       "     'treatment_tags': [],\n",
       "     'visited': False,\n",
       "     'removed_by': None,\n",
       "     'num_reports': None,\n",
       "     'distinguished': None,\n",
       "     'subreddit_id': 't5_36en4',\n",
       "     'author_is_blocked': False,\n",
       "     'mod_reason_by': None,\n",
       "     'removal_reason': None,\n",
       "     'link_flair_background_color': '#ff4500',\n",
       "     'id': '1cu0zg1',\n",
       "     'is_robot_indexable': True,\n",
       "     'report_reasons': None,\n",
       "     'author': 'ut0mt8',\n",
       "     'discussion_type': None,\n",
       "     'num_comments': 7,\n",
       "     'send_replies': True,\n",
       "     'whitelist_status': 'all_ads',\n",
       "     'contest_mode': False,\n",
       "     'mod_reports': [],\n",
       "     'author_patreon_flair': False,\n",
       "     'author_flair_text_color': None,\n",
       "     'permalink': '/r/dataengineering/comments/1cu0zg1/dataengineering_modeling_questions/',\n",
       "     'parent_whitelist_status': 'all_ads',\n",
       "     'stickied': False,\n",
       "     'url': 'https://www.reddit.com/r/dataengineering/comments/1cu0zg1/dataengineering_modeling_questions/',\n",
       "     'subreddit_subscribers': 185845,\n",
       "     'created_utc': 1715937977.0,\n",
       "     'num_crossposts': 0,\n",
       "     'media': None,\n",
       "     'is_video': False}},\n",
       "   {'kind': 't3',\n",
       "    'data': {'approved_at_utc': None,\n",
       "     'subreddit': 'dataengineering',\n",
       "     'selftext': 'I was just very curious, how AI can affect dataengineering. As in which all area in a standard DE project can be replaced by AI.\\nThe reason I am asking this to focus on  developing skills for AI which are DE oriented.',\n",
       "     'author_fullname': 't2_f363j2vr5',\n",
       "     'saved': False,\n",
       "     'mod_reason_title': None,\n",
       "     'gilded': 0,\n",
       "     'clicked': False,\n",
       "     'title': 'AI in dataengineering',\n",
       "     'link_flair_richtext': [],\n",
       "     'subreddit_name_prefixed': 'r/dataengineering',\n",
       "     'hidden': False,\n",
       "     'pwls': 6,\n",
       "     'link_flair_css_class': '',\n",
       "     'downs': 0,\n",
       "     'thumbnail_height': None,\n",
       "     'top_awarded_type': None,\n",
       "     'hide_score': False,\n",
       "     'name': 't3_17i4cb6',\n",
       "     'quarantine': False,\n",
       "     'link_flair_text_color': 'light',\n",
       "     'upvote_ratio': 0.57,\n",
       "     'author_flair_background_color': None,\n",
       "     'subreddit_type': 'public',\n",
       "     'ups': 1,\n",
       "     'total_awards_received': 0,\n",
       "     'media_embed': {},\n",
       "     'thumbnail_width': None,\n",
       "     'author_flair_template_id': None,\n",
       "     'is_original_content': False,\n",
       "     'user_reports': [],\n",
       "     'secure_media': None,\n",
       "     'is_reddit_media_domain': False,\n",
       "     'is_meta': False,\n",
       "     'category': None,\n",
       "     'secure_media_embed': {},\n",
       "     'link_flair_text': 'Discussion',\n",
       "     'can_mod_post': False,\n",
       "     'score': 1,\n",
       "     'approved_by': None,\n",
       "     'is_created_from_ads_ui': False,\n",
       "     'author_premium': False,\n",
       "     'thumbnail': 'self',\n",
       "     'edited': False,\n",
       "     'author_flair_css_class': None,\n",
       "     'author_flair_richtext': [],\n",
       "     'gildings': {},\n",
       "     'content_categories': None,\n",
       "     'is_self': True,\n",
       "     'mod_note': None,\n",
       "     'created': 1698461282.0,\n",
       "     'link_flair_type': 'text',\n",
       "     'wls': 6,\n",
       "     'removed_by_category': None,\n",
       "     'banned_by': None,\n",
       "     'author_flair_type': 'text',\n",
       "     'domain': 'self.dataengineering',\n",
       "     'allow_live_comments': False,\n",
       "     'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was just very curious, how AI can affect dataengineering. As in which all area in a standard DE project can be replaced by AI.\\nThe reason I am asking this to focus on  developing skills for AI which are DE oriented.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       "     'likes': None,\n",
       "     'suggested_sort': None,\n",
       "     'banned_at_utc': None,\n",
       "     'view_count': None,\n",
       "     'archived': True,\n",
       "     'no_follow': False,\n",
       "     'is_crosspostable': True,\n",
       "     'pinned': False,\n",
       "     'over_18': False,\n",
       "     'all_awardings': [],\n",
       "     'awarders': [],\n",
       "     'media_only': False,\n",
       "     'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f',\n",
       "     'can_gild': False,\n",
       "     'spoiler': False,\n",
       "     'locked': False,\n",
       "     'author_flair_text': None,\n",
       "     'treatment_tags': [],\n",
       "     'visited': False,\n",
       "     'removed_by': None,\n",
       "     'num_reports': None,\n",
       "     'distinguished': None,\n",
       "     'subreddit_id': 't5_36en4',\n",
       "     'author_is_blocked': False,\n",
       "     'mod_reason_by': None,\n",
       "     'removal_reason': None,\n",
       "     'link_flair_background_color': '#ff4500',\n",
       "     'id': '17i4cb6',\n",
       "     'is_robot_indexable': True,\n",
       "     'report_reasons': None,\n",
       "     'author': 'RogerRockzz',\n",
       "     'discussion_type': None,\n",
       "     'num_comments': 11,\n",
       "     'send_replies': True,\n",
       "     'whitelist_status': 'all_ads',\n",
       "     'contest_mode': False,\n",
       "     'mod_reports': [],\n",
       "     'author_patreon_flair': False,\n",
       "     'author_flair_text_color': None,\n",
       "     'permalink': '/r/dataengineering/comments/17i4cb6/ai_in_dataengineering/',\n",
       "     'parent_whitelist_status': 'all_ads',\n",
       "     'stickied': False,\n",
       "     'url': 'https://www.reddit.com/r/dataengineering/comments/17i4cb6/ai_in_dataengineering/',\n",
       "     'subreddit_subscribers': 185845,\n",
       "     'created_utc': 1698461282.0,\n",
       "     'num_crossposts': 0,\n",
       "     'media': None,\n",
       "     'is_video': False}},\n",
       "   {'kind': 't3',\n",
       "    'data': {'approved_at_utc': None,\n",
       "     'subreddit': 'snowflake',\n",
       "     'selftext': '',\n",
       "     'author_fullname': 't2_3kxbd',\n",
       "     'saved': False,\n",
       "     'mod_reason_title': None,\n",
       "     'gilded': 0,\n",
       "     'clicked': False,\n",
       "     'title': '/r/dataengineering discussing Snowpipe',\n",
       "     'link_flair_richtext': [],\n",
       "     'subreddit_name_prefixed': 'r/snowflake',\n",
       "     'hidden': False,\n",
       "     'pwls': 6,\n",
       "     'link_flair_css_class': None,\n",
       "     'downs': 0,\n",
       "     'thumbnail_height': None,\n",
       "     'top_awarded_type': None,\n",
       "     'hide_score': False,\n",
       "     'name': 't3_18e0pb4',\n",
       "     'quarantine': False,\n",
       "     'link_flair_text_color': 'dark',\n",
       "     'upvote_ratio': 1.0,\n",
       "     'author_flair_background_color': '',\n",
       "     'subreddit_type': 'public',\n",
       "     'ups': 2,\n",
       "     'total_awards_received': 0,\n",
       "     'media_embed': {},\n",
       "     'thumbnail_width': None,\n",
       "     'author_flair_template_id': None,\n",
       "     'is_original_content': False,\n",
       "     'user_reports': [],\n",
       "     'secure_media': None,\n",
       "     'is_reddit_media_domain': False,\n",
       "     'is_meta': False,\n",
       "     'category': None,\n",
       "     'secure_media_embed': {},\n",
       "     'link_flair_text': None,\n",
       "     'can_mod_post': False,\n",
       "     'score': 2,\n",
       "     'approved_by': None,\n",
       "     'is_created_from_ads_ui': False,\n",
       "     'author_premium': False,\n",
       "     'thumbnail': 'default',\n",
       "     'edited': False,\n",
       "     'author_flair_css_class': None,\n",
       "     'author_flair_richtext': [],\n",
       "     'gildings': {},\n",
       "     'content_categories': None,\n",
       "     'is_self': False,\n",
       "     'mod_note': None,\n",
       "     'created': 1702080812.0,\n",
       "     'link_flair_type': 'text',\n",
       "     'wls': 6,\n",
       "     'removed_by_category': None,\n",
       "     'banned_by': None,\n",
       "     'author_flair_type': 'text',\n",
       "     'domain': 'reddit.com',\n",
       "     'allow_live_comments': False,\n",
       "     'selftext_html': None,\n",
       "     'likes': None,\n",
       "     'suggested_sort': None,\n",
       "     'banned_at_utc': None,\n",
       "     'url_overridden_by_dest': 'https://www.reddit.com/r/dataengineering/comments/18dgo8q/experience_with_snowpipe/',\n",
       "     'view_count': None,\n",
       "     'archived': False,\n",
       "     'no_follow': False,\n",
       "     'is_crosspostable': True,\n",
       "     'pinned': False,\n",
       "     'over_18': False,\n",
       "     'all_awardings': [],\n",
       "     'awarders': [],\n",
       "     'media_only': False,\n",
       "     'can_gild': False,\n",
       "     'spoiler': False,\n",
       "     'locked': False,\n",
       "     'author_flair_text': '❄️',\n",
       "     'treatment_tags': [],\n",
       "     'visited': False,\n",
       "     'removed_by': None,\n",
       "     'num_reports': None,\n",
       "     'distinguished': None,\n",
       "     'subreddit_id': 't5_318fi',\n",
       "     'author_is_blocked': False,\n",
       "     'mod_reason_by': None,\n",
       "     'removal_reason': None,\n",
       "     'link_flair_background_color': '',\n",
       "     'id': '18e0pb4',\n",
       "     'is_robot_indexable': True,\n",
       "     'report_reasons': None,\n",
       "     'author': 'fhoffa',\n",
       "     'discussion_type': None,\n",
       "     'num_comments': 0,\n",
       "     'send_replies': True,\n",
       "     'whitelist_status': 'all_ads',\n",
       "     'contest_mode': False,\n",
       "     'mod_reports': [],\n",
       "     'author_patreon_flair': False,\n",
       "     'author_flair_text_color': 'dark',\n",
       "     'permalink': '/r/snowflake/comments/18e0pb4/rdataengineering_discussing_snowpipe/',\n",
       "     'parent_whitelist_status': 'all_ads',\n",
       "     'stickied': False,\n",
       "     'url': 'https://www.reddit.com/r/dataengineering/comments/18dgo8q/experience_with_snowpipe/',\n",
       "     'subreddit_subscribers': 10739,\n",
       "     'created_utc': 1702080812.0,\n",
       "     'num_crossposts': 0,\n",
       "     'media': None,\n",
       "     'is_video': False}},\n",
       "   {'kind': 't3',\n",
       "    'data': {'approved_at_utc': None,\n",
       "     'subreddit': 'DataEngineeringPH',\n",
       "     'selftext': 'we now have a home page! ',\n",
       "     'author_fullname': 't2_56myc',\n",
       "     'saved': False,\n",
       "     'mod_reason_title': None,\n",
       "     'gilded': 0,\n",
       "     'clicked': False,\n",
       "     'title': 'https://dataengineering.ph/',\n",
       "     'link_flair_richtext': [],\n",
       "     'subreddit_name_prefixed': 'r/DataEngineeringPH',\n",
       "     'hidden': False,\n",
       "     'pwls': None,\n",
       "     'link_flair_css_class': None,\n",
       "     'downs': 0,\n",
       "     'thumbnail_height': None,\n",
       "     'top_awarded_type': None,\n",
       "     'hide_score': False,\n",
       "     'name': 't3_1aj60ic',\n",
       "     'quarantine': False,\n",
       "     'link_flair_text_color': 'dark',\n",
       "     'upvote_ratio': 1.0,\n",
       "     'author_flair_background_color': None,\n",
       "     'subreddit_type': 'public',\n",
       "     'ups': 4,\n",
       "     'total_awards_received': 0,\n",
       "     'media_embed': {},\n",
       "     'thumbnail_width': None,\n",
       "     'author_flair_template_id': None,\n",
       "     'is_original_content': False,\n",
       "     'user_reports': [],\n",
       "     'secure_media': None,\n",
       "     'is_reddit_media_domain': False,\n",
       "     'is_meta': False,\n",
       "     'category': None,\n",
       "     'secure_media_embed': {},\n",
       "     'link_flair_text': None,\n",
       "     'can_mod_post': False,\n",
       "     'score': 4,\n",
       "     'approved_by': None,\n",
       "     'is_created_from_ads_ui': False,\n",
       "     'author_premium': False,\n",
       "     'thumbnail': 'self',\n",
       "     'edited': False,\n",
       "     'author_flair_css_class': None,\n",
       "     'author_flair_richtext': [],\n",
       "     'gildings': {},\n",
       "     'content_categories': None,\n",
       "     'is_self': True,\n",
       "     'mod_note': None,\n",
       "     'created': 1707101192.0,\n",
       "     'link_flair_type': 'text',\n",
       "     'wls': None,\n",
       "     'removed_by_category': None,\n",
       "     'banned_by': None,\n",
       "     'author_flair_type': 'text',\n",
       "     'domain': 'self.DataEngineeringPH',\n",
       "     'allow_live_comments': False,\n",
       "     'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;we now have a home page! &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       "     'likes': None,\n",
       "     'suggested_sort': None,\n",
       "     'banned_at_utc': None,\n",
       "     'view_count': None,\n",
       "     'archived': False,\n",
       "     'no_follow': False,\n",
       "     'is_crosspostable': True,\n",
       "     'pinned': False,\n",
       "     'over_18': False,\n",
       "     'all_awardings': [],\n",
       "     'awarders': [],\n",
       "     'media_only': False,\n",
       "     'can_gild': False,\n",
       "     'spoiler': False,\n",
       "     'locked': False,\n",
       "     'author_flair_text': None,\n",
       "     'treatment_tags': [],\n",
       "     'visited': False,\n",
       "     'removed_by': None,\n",
       "     'num_reports': None,\n",
       "     'distinguished': None,\n",
       "     'subreddit_id': 't5_am2z20',\n",
       "     'author_is_blocked': False,\n",
       "     'mod_reason_by': None,\n",
       "     'removal_reason': None,\n",
       "     'link_flair_background_color': '',\n",
       "     'id': '1aj60ic',\n",
       "     'is_robot_indexable': True,\n",
       "     'report_reasons': None,\n",
       "     'author': 'saintmichel',\n",
       "     'discussion_type': None,\n",
       "     'num_comments': 0,\n",
       "     'send_replies': True,\n",
       "     'whitelist_status': None,\n",
       "     'contest_mode': False,\n",
       "     'mod_reports': [],\n",
       "     'author_patreon_flair': False,\n",
       "     'author_flair_text_color': None,\n",
       "     'permalink': '/r/DataEngineeringPH/comments/1aj60ic/httpsdataengineeringph/',\n",
       "     'parent_whitelist_status': None,\n",
       "     'stickied': False,\n",
       "     'url': 'https://www.reddit.com/r/DataEngineeringPH/comments/1aj60ic/httpsdataengineeringph/',\n",
       "     'subreddit_subscribers': 706,\n",
       "     'created_utc': 1707101192.0,\n",
       "     'num_crossposts': 0,\n",
       "     'media': None,\n",
       "     'is_video': False}},\n",
       "   {'kind': 't3',\n",
       "    'data': {'approved_at_utc': None,\n",
       "     'subreddit': 'dataengineering',\n",
       "     'selftext': 'Hello, my company is currently storing a ton of data in databricks and i would like to do “stuff” with this data. Like analysis, maybe some graphs, maybe some code to get some specific metrics. Not being a dataengineer (but im a developer) what are some things i can learn in this space to join meetings and not be 100% lost. Is this one of pandas use cases? ',\n",
       "     'author_fullname': 't2_2gjyr66m',\n",
       "     'saved': False,\n",
       "     'mod_reason_title': None,\n",
       "     'gilded': 0,\n",
       "     'clicked': False,\n",
       "     'title': 'Databricks for non dataengineers',\n",
       "     'link_flair_richtext': [],\n",
       "     'subreddit_name_prefixed': 'r/dataengineering',\n",
       "     'hidden': False,\n",
       "     'pwls': 6,\n",
       "     'link_flair_css_class': '',\n",
       "     'downs': 0,\n",
       "     'thumbnail_height': None,\n",
       "     'top_awarded_type': None,\n",
       "     'hide_score': False,\n",
       "     'name': 't3_18jb2ze',\n",
       "     'quarantine': False,\n",
       "     'link_flair_text_color': 'light',\n",
       "     'upvote_ratio': 1.0,\n",
       "     'author_flair_background_color': None,\n",
       "     'subreddit_type': 'public',\n",
       "     'ups': 4,\n",
       "     'total_awards_received': 0,\n",
       "     'media_embed': {},\n",
       "     'thumbnail_width': None,\n",
       "     'author_flair_template_id': None,\n",
       "     'is_original_content': False,\n",
       "     'user_reports': [],\n",
       "     'secure_media': None,\n",
       "     'is_reddit_media_domain': False,\n",
       "     'is_meta': False,\n",
       "     'category': None,\n",
       "     'secure_media_embed': {},\n",
       "     'link_flair_text': 'Help',\n",
       "     'can_mod_post': False,\n",
       "     'score': 4,\n",
       "     'approved_by': None,\n",
       "     'is_created_from_ads_ui': False,\n",
       "     'author_premium': False,\n",
       "     'thumbnail': 'self',\n",
       "     'edited': 1702676793.0,\n",
       "     'author_flair_css_class': None,\n",
       "     'author_flair_richtext': [],\n",
       "     'gildings': {},\n",
       "     'content_categories': None,\n",
       "     'is_self': True,\n",
       "     'mod_note': None,\n",
       "     'created': 1702676517.0,\n",
       "     'link_flair_type': 'text',\n",
       "     'wls': 6,\n",
       "     'removed_by_category': None,\n",
       "     'banned_by': None,\n",
       "     'author_flair_type': 'text',\n",
       "     'domain': 'self.dataengineering',\n",
       "     'allow_live_comments': False,\n",
       "     'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, my company is currently storing a ton of data in databricks and i would like to do “stuff” with this data. Like analysis, maybe some graphs, maybe some code to get some specific metrics. Not being a dataengineer (but im a developer) what are some things i can learn in this space to join meetings and not be 100% lost. Is this one of pandas use cases? &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       "     'likes': None,\n",
       "     'suggested_sort': None,\n",
       "     'banned_at_utc': None,\n",
       "     'view_count': None,\n",
       "     'archived': False,\n",
       "     'no_follow': False,\n",
       "     'is_crosspostable': True,\n",
       "     'pinned': False,\n",
       "     'over_18': False,\n",
       "     'all_awardings': [],\n",
       "     'awarders': [],\n",
       "     'media_only': False,\n",
       "     'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3',\n",
       "     'can_gild': False,\n",
       "     'spoiler': False,\n",
       "     'locked': False,\n",
       "     'author_flair_text': None,\n",
       "     'treatment_tags': [],\n",
       "     'visited': False,\n",
       "     'removed_by': None,\n",
       "     'num_reports': None,\n",
       "     'distinguished': None,\n",
       "     'subreddit_id': 't5_36en4',\n",
       "     'author_is_blocked': False,\n",
       "     'mod_reason_by': None,\n",
       "     'removal_reason': None,\n",
       "     'link_flair_background_color': '#ea0027',\n",
       "     'id': '18jb2ze',\n",
       "     'is_robot_indexable': True,\n",
       "     'report_reasons': None,\n",
       "     'author': 'SuperLucas2000',\n",
       "     'discussion_type': None,\n",
       "     'num_comments': 6,\n",
       "     'send_replies': True,\n",
       "     'whitelist_status': 'all_ads',\n",
       "     'contest_mode': False,\n",
       "     'mod_reports': [],\n",
       "     'author_patreon_flair': False,\n",
       "     'author_flair_text_color': None,\n",
       "     'permalink': '/r/dataengineering/comments/18jb2ze/databricks_for_non_dataengineers/',\n",
       "     'parent_whitelist_status': 'all_ads',\n",
       "     'stickied': False,\n",
       "     'url': 'https://www.reddit.com/r/dataengineering/comments/18jb2ze/databricks_for_non_dataengineers/',\n",
       "     'subreddit_subscribers': 185845,\n",
       "     'created_utc': 1702676517.0,\n",
       "     'num_crossposts': 0,\n",
       "     'media': None,\n",
       "     'is_video': False}},\n",
       "   {'kind': 't3',\n",
       "    'data': {'approved_at_utc': None,\n",
       "     'subreddit': 'dataengineering',\n",
       "     'selftext': \"Hi, fellow data engineers!\\n\\nI've built a tool to find the best resources shared on r/dataengineering as well as other subreddits.Here is the link: [https://www.gembase.ai/search?q=data+engineering](https://www.gembase.ai/search?q=data+engineering)\\n\\n**Architecture**\\n\\nI gathered all the archive data from Reddit.\\n\\n* Then extracted URLs with Go on a big EC2 machine.\\n* The screenshots and titles were scraped using Python + Playwright hosted on \\\\~1000 ECS tasks.\\n* The recommendations were offline computed with R + Tidyverse.\\n\\nI hope you will enjoy it. Feedback and questions are really appreciated.\",\n",
       "     'author_fullname': 't2_21q5bign',\n",
       "     'saved': False,\n",
       "     'mod_reason_title': None,\n",
       "     'gilded': 0,\n",
       "     'clicked': False,\n",
       "     'title': 'The most shared resources from r/dataengineering',\n",
       "     'link_flair_richtext': [],\n",
       "     'subreddit_name_prefixed': 'r/dataengineering',\n",
       "     'hidden': False,\n",
       "     'pwls': 6,\n",
       "     'link_flair_css_class': '',\n",
       "     'downs': 0,\n",
       "     'thumbnail_height': None,\n",
       "     'top_awarded_type': None,\n",
       "     'hide_score': False,\n",
       "     'name': 't3_zebb3o',\n",
       "     'quarantine': False,\n",
       "     'link_flair_text_color': 'light',\n",
       "     'upvote_ratio': 1.0,\n",
       "     'author_flair_background_color': None,\n",
       "     'subreddit_type': 'public',\n",
       "     'ups': 176,\n",
       "     'total_awards_received': 0,\n",
       "     'media_embed': {},\n",
       "     'thumbnail_width': None,\n",
       "     'author_flair_template_id': None,\n",
       "     'is_original_content': False,\n",
       "     'user_reports': [],\n",
       "     'secure_media': None,\n",
       "     'is_reddit_media_domain': False,\n",
       "     'is_meta': False,\n",
       "     'category': None,\n",
       "     'secure_media_embed': {},\n",
       "     'link_flair_text': 'Blog',\n",
       "     'can_mod_post': False,\n",
       "     'score': 176,\n",
       "     'approved_by': None,\n",
       "     'is_created_from_ads_ui': False,\n",
       "     'author_premium': True,\n",
       "     'thumbnail': 'self',\n",
       "     'edited': 1682877797.0,\n",
       "     'author_flair_css_class': None,\n",
       "     'author_flair_richtext': [],\n",
       "     'gildings': {},\n",
       "     'content_categories': None,\n",
       "     'is_self': True,\n",
       "     'mod_note': None,\n",
       "     'created': 1670344725.0,\n",
       "     'link_flair_type': 'text',\n",
       "     'wls': 6,\n",
       "     'removed_by_category': None,\n",
       "     'banned_by': None,\n",
       "     'author_flair_type': 'text',\n",
       "     'domain': 'self.dataengineering',\n",
       "     'allow_live_comments': False,\n",
       "     'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, fellow data engineers!&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve built a tool to find the best resources shared on &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; as well as other subreddits.Here is the link: &lt;a href=\"https://www.gembase.ai/search?q=data+engineering\"&gt;https://www.gembase.ai/search?q=data+engineering&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Architecture&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I gathered all the archive data from Reddit.&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Then extracted URLs with Go on a big EC2 machine.&lt;/li&gt;\\n&lt;li&gt;The screenshots and titles were scraped using Python + Playwright hosted on ~1000 ECS tasks.&lt;/li&gt;\\n&lt;li&gt;The recommendations were offline computed with R + Tidyverse.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;I hope you will enjoy it. Feedback and questions are really appreciated.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       "     'likes': None,\n",
       "     'suggested_sort': None,\n",
       "     'banned_at_utc': None,\n",
       "     'view_count': None,\n",
       "     'archived': True,\n",
       "     'no_follow': False,\n",
       "     'is_crosspostable': True,\n",
       "     'pinned': False,\n",
       "     'over_18': False,\n",
       "     'all_awardings': [],\n",
       "     'awarders': [],\n",
       "     'media_only': False,\n",
       "     'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313',\n",
       "     'can_gild': False,\n",
       "     'spoiler': False,\n",
       "     'locked': False,\n",
       "     'author_flair_text': None,\n",
       "     'treatment_tags': [],\n",
       "     'visited': False,\n",
       "     'removed_by': None,\n",
       "     'num_reports': None,\n",
       "     'distinguished': None,\n",
       "     'subreddit_id': 't5_36en4',\n",
       "     'author_is_blocked': False,\n",
       "     'mod_reason_by': None,\n",
       "     'removal_reason': None,\n",
       "     'link_flair_background_color': '#0079d3',\n",
       "     'id': 'zebb3o',\n",
       "     'is_robot_indexable': True,\n",
       "     'report_reasons': None,\n",
       "     'author': 'flpezet',\n",
       "     'discussion_type': None,\n",
       "     'num_comments': 22,\n",
       "     'send_replies': True,\n",
       "     'whitelist_status': 'all_ads',\n",
       "     'contest_mode': False,\n",
       "     'mod_reports': [],\n",
       "     'author_patreon_flair': False,\n",
       "     'author_flair_text_color': None,\n",
       "     'permalink': '/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/',\n",
       "     'parent_whitelist_status': 'all_ads',\n",
       "     'stickied': False,\n",
       "     'url': 'https://www.reddit.com/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/',\n",
       "     'subreddit_subscribers': 185845,\n",
       "     'created_utc': 1670344725.0,\n",
       "     'num_crossposts': 0,\n",
       "     'media': None,\n",
       "     'is_video': False}},\n",
       "   {'kind': 't3',\n",
       "    'data': {'approved_at_utc': None,\n",
       "     'subreddit': 'developersIndia',\n",
       "     'selftext': \"Hi everybody . I have been preparing for data science/ data engineer roles for past five months and got only four call backs couldn't clear OA's for three.\\n\\n  \\nHow is your job hunt going on and how do you prepare for DSA , statistics and EDA kind of questions ?\\n\\nWhat is your preparation strategy for acing the OA's and what hurdles are you facing for your YOE in the market ? \",\n",
       "     'author_fullname': 't2_r4eilh96',\n",
       "     'saved': False,\n",
       "     'mod_reason_title': None,\n",
       "     'gilded': 0,\n",
       "     'clicked': False,\n",
       "     'title': 'How is your job hunt  for datascience/dataengineer roles ?',\n",
       "     'link_flair_richtext': [{'e': 'text', 't': 'Career'}],\n",
       "     'subreddit_name_prefixed': 'r/developersIndia',\n",
       "     'hidden': False,\n",
       "     'pwls': 6,\n",
       "     'link_flair_css_class': '',\n",
       "     'downs': 0,\n",
       "     'thumbnail_height': None,\n",
       "     'top_awarded_type': None,\n",
       "     'hide_score': False,\n",
       "     'name': 't3_1ctzzba',\n",
       "     'quarantine': False,\n",
       "     'link_flair_text_color': 'light',\n",
       "     'upvote_ratio': 1.0,\n",
       "     'author_flair_background_color': None,\n",
       "     'subreddit_type': 'public',\n",
       "     'ups': 2,\n",
       "     'total_awards_received': 0,\n",
       "     'media_embed': {},\n",
       "     'thumbnail_width': None,\n",
       "     'author_flair_template_id': None,\n",
       "     'is_original_content': False,\n",
       "     'user_reports': [],\n",
       "     'secure_media': None,\n",
       "     'is_reddit_media_domain': False,\n",
       "     'is_meta': False,\n",
       "     'category': None,\n",
       "     'secure_media_embed': {},\n",
       "     'link_flair_text': 'Career',\n",
       "     'can_mod_post': False,\n",
       "     'score': 2,\n",
       "     'approved_by': None,\n",
       "     'is_created_from_ads_ui': False,\n",
       "     'author_premium': False,\n",
       "     'thumbnail': 'self',\n",
       "     'edited': False,\n",
       "     'author_flair_css_class': None,\n",
       "     'author_flair_richtext': [],\n",
       "     'gildings': {},\n",
       "     'content_categories': None,\n",
       "     'is_self': True,\n",
       "     'mod_note': None,\n",
       "     'created': 1715933461.0,\n",
       "     'link_flair_type': 'richtext',\n",
       "     'wls': 6,\n",
       "     'removed_by_category': None,\n",
       "     'banned_by': None,\n",
       "     'author_flair_type': 'text',\n",
       "     'domain': 'self.developersIndia',\n",
       "     'allow_live_comments': False,\n",
       "     'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody . I have been preparing for data science/ data engineer roles for past five months and got only four call backs couldn&amp;#39;t clear OA&amp;#39;s for three.&lt;/p&gt;\\n\\n&lt;p&gt;How is your job hunt going on and how do you prepare for DSA , statistics and EDA kind of questions ?&lt;/p&gt;\\n\\n&lt;p&gt;What is your preparation strategy for acing the OA&amp;#39;s and what hurdles are you facing for your YOE in the market ? &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       "     'likes': None,\n",
       "     'suggested_sort': 'confidence',\n",
       "     'banned_at_utc': None,\n",
       "     'view_count': None,\n",
       "     'archived': False,\n",
       "     'no_follow': False,\n",
       "     'is_crosspostable': True,\n",
       "     'pinned': False,\n",
       "     'over_18': False,\n",
       "     'all_awardings': [],\n",
       "     'awarders': [],\n",
       "     'media_only': False,\n",
       "     'link_flair_template_id': '03e7fc80-5628-11ea-9977-0e3f7ea7151f',\n",
       "     'can_gild': False,\n",
       "     'spoiler': False,\n",
       "     'locked': False,\n",
       "     'author_flair_text': None,\n",
       "     'treatment_tags': [],\n",
       "     'visited': False,\n",
       "     'removed_by': None,\n",
       "     'num_reports': None,\n",
       "     'distinguished': None,\n",
       "     'subreddit_id': 't5_2dfnk0',\n",
       "     'author_is_blocked': False,\n",
       "     'mod_reason_by': None,\n",
       "     'removal_reason': None,\n",
       "     'link_flair_background_color': '#5a74cc',\n",
       "     'id': '1ctzzba',\n",
       "     'is_robot_indexable': True,\n",
       "     'report_reasons': None,\n",
       "     'author': 'Left_Tip_7300',\n",
       "     'discussion_type': None,\n",
       "     'num_comments': 2,\n",
       "     'send_replies': True,\n",
       "     'whitelist_status': 'all_ads',\n",
       "     'contest_mode': False,\n",
       "     'mod_reports': [],\n",
       "     'author_patreon_flair': False,\n",
       "     'author_flair_text_color': None,\n",
       "     'permalink': '/r/developersIndia/comments/1ctzzba/how_is_your_job_hunt_for_datasciencedataengineer/',\n",
       "     'parent_whitelist_status': 'all_ads',\n",
       "     'stickied': False,\n",
       "     'url': 'https://www.reddit.com/r/developersIndia/comments/1ctzzba/how_is_your_job_hunt_for_datasciencedataengineer/',\n",
       "     'subreddit_subscribers': 665689,\n",
       "     'created_utc': 1715933461.0,\n",
       "     'num_crossposts': 0,\n",
       "     'media': None,\n",
       "     'is_video': False}},\n",
       "   {'kind': 't3',\n",
       "    'data': {'approved_at_utc': None,\n",
       "     'subreddit': 'dataengineering',\n",
       "     'selftext': 'Hi all, I just got my position as DataOps from previous job as DataEngineer.   \\n\\n\\nI need some ideas from you about what are daily tasks, responsibilities of DataOps vs DataEngineer and where is the clear cut between the 2 ?  \\n\\n\\nCheers',\n",
       "     'author_fullname': 't2_93s65yqu',\n",
       "     'saved': False,\n",
       "     'mod_reason_title': None,\n",
       "     'gilded': 0,\n",
       "     'clicked': False,\n",
       "     'title': 'DataEngineering --&gt; DataOps',\n",
       "     'link_flair_richtext': [],\n",
       "     'subreddit_name_prefixed': 'r/dataengineering',\n",
       "     'hidden': False,\n",
       "     'pwls': 6,\n",
       "     'link_flair_css_class': '',\n",
       "     'downs': 0,\n",
       "     'thumbnail_height': None,\n",
       "     'top_awarded_type': None,\n",
       "     'hide_score': False,\n",
       "     'name': 't3_12kpq9i',\n",
       "     'quarantine': False,\n",
       "     'link_flair_text_color': 'light',\n",
       "     'upvote_ratio': 0.67,\n",
       "     'author_flair_background_color': None,\n",
       "     'subreddit_type': 'public',\n",
       "     'ups': 1,\n",
       "     'total_awards_received': 0,\n",
       "     'media_embed': {},\n",
       "     'thumbnail_width': None,\n",
       "     'author_flair_template_id': None,\n",
       "     'is_original_content': False,\n",
       "     'user_reports': [],\n",
       "     'secure_media': None,\n",
       "     'is_reddit_media_domain': False,\n",
       "     'is_meta': False,\n",
       "     'category': None,\n",
       "     'secure_media_embed': {},\n",
       "     'link_flair_text': 'Career',\n",
       "     'can_mod_post': False,\n",
       "     'score': 1,\n",
       "     'approved_by': None,\n",
       "     'is_created_from_ads_ui': False,\n",
       "     'author_premium': False,\n",
       "     'thumbnail': 'self',\n",
       "     'edited': False,\n",
       "     'author_flair_css_class': None,\n",
       "     'author_flair_richtext': [],\n",
       "     'gildings': {},\n",
       "     'content_categories': None,\n",
       "     'is_self': True,\n",
       "     'mod_note': None,\n",
       "     'created': 1681393483.0,\n",
       "     'link_flair_type': 'text',\n",
       "     'wls': 6,\n",
       "     'removed_by_category': None,\n",
       "     'banned_by': None,\n",
       "     'author_flair_type': 'text',\n",
       "     'domain': 'self.dataengineering',\n",
       "     'allow_live_comments': False,\n",
       "     'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I just got my position as DataOps from previous job as DataEngineer.   &lt;/p&gt;\\n\\n&lt;p&gt;I need some ideas from you about what are daily tasks, responsibilities of DataOps vs DataEngineer and where is the clear cut between the 2 ?  &lt;/p&gt;\\n\\n&lt;p&gt;Cheers&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       "     'likes': None,\n",
       "     'suggested_sort': None,\n",
       "     'banned_at_utc': None,\n",
       "     'view_count': None,\n",
       "     'archived': True,\n",
       "     'no_follow': True,\n",
       "     'is_crosspostable': True,\n",
       "     'pinned': False,\n",
       "     'over_18': False,\n",
       "     'all_awardings': [],\n",
       "     'awarders': [],\n",
       "     'media_only': False,\n",
       "     'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3',\n",
       "     'can_gild': False,\n",
       "     'spoiler': False,\n",
       "     'locked': False,\n",
       "     'author_flair_text': None,\n",
       "     'treatment_tags': [],\n",
       "     'visited': False,\n",
       "     'removed_by': None,\n",
       "     'num_reports': None,\n",
       "     'distinguished': None,\n",
       "     'subreddit_id': 't5_36en4',\n",
       "     'author_is_blocked': False,\n",
       "     'mod_reason_by': None,\n",
       "     'removal_reason': None,\n",
       "     'link_flair_background_color': '#349e48',\n",
       "     'id': '12kpq9i',\n",
       "     'is_robot_indexable': True,\n",
       "     'report_reasons': None,\n",
       "     'author': 'Striking_Athlete5685',\n",
       "     'discussion_type': None,\n",
       "     'num_comments': 8,\n",
       "     'send_replies': True,\n",
       "     'whitelist_status': 'all_ads',\n",
       "     'contest_mode': False,\n",
       "     'mod_reports': [],\n",
       "     'author_patreon_flair': False,\n",
       "     'author_flair_text_color': None,\n",
       "     'permalink': '/r/dataengineering/comments/12kpq9i/dataengineering_dataops/',\n",
       "     'parent_whitelist_status': 'all_ads',\n",
       "     'stickied': False,\n",
       "     'url': 'https://www.reddit.com/r/dataengineering/comments/12kpq9i/dataengineering_dataops/',\n",
       "     'subreddit_subscribers': 185845,\n",
       "     'created_utc': 1681393483.0,\n",
       "     'num_crossposts': 0,\n",
       "     'media': None,\n",
       "     'is_video': False}}],\n",
       "  'before': None}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {**headers,**{\"Authorization\": f\"bearer {reddit_token}\"}}\n",
    "\n",
    "search_query = 'dataengineering'\n",
    "search = requests.get(f'https://oauth.reddit.com/r/all/search.json?q={search_query}&limit=10', headers=headers)\n",
    "r_json = search.json()\n",
    "r_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'User-Agent': 'test-app by u/mjcolon218',\n",
       " 'Authorization': 'bearer eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJ1c2VyIiwiZXhwIjoxNzE2Njc0MzE3LjY3Mzc3OCwiaWF0IjoxNzE2NTg3OTE3LjY3Mzc3OCwianRpIjoibThpMjU0ZEROR3VxdWNOVldzMFlEZGZKaDBsbC1RIiwiY2lkIjoiNDFrNm9XM1VUaHBLVmY2eEQ1T19NZyIsImxpZCI6InQyX3ZtdHVwNXluIiwiYWlkIjoidDJfdm10dXA1eW4iLCJsY2EiOjE2NzQyNDY1NTMwMDAsInNjcCI6ImVKeUtWdEpTaWdVRUFBRF9fd056QVNjIiwiZmxvIjo5fQ.AuWiFxSueWk1-tMBPF1kS6pUbiBxSmDZdG93ysiLqN-jj7BQ6-mzF8J1W7pvL_MjxR1LsptFpBIZ37V8Pl3Ov3u1oA_MnuY1mcSIkqb4ZKbkSRLim4m9TQUbdoSnw9UjIhzUdXIS7J6Oh044_s74qClpl2dQcHAVaV2e8oDBfVJoZaYCDgsya9fsLsnu9tpXO4wz6e4x57ivC6f9pplUVngUYn2qBAB5TuNSeB1LFTSWDRt46oUKx9piaIgq7kwTFF-sVzpMjAurD2odLcVJTprKfyQQ2Smkfxl8ggjOlAGgmQlAJ6glkhzsrAej49NPFPEneRdNtrxObDAi6DTwUg'}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscsriber_count_list = []\n",
    "created_utc_list = []\n",
    "is_video_list = []\n",
    "post_score_list = []\n",
    "over_18_list = []\n",
    "author_list = []\n",
    "num_of_comments_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How true is this thing of getting “blacklisted” for wrong titles on resumes?\n",
      "19ab6dx\n",
      "DataEngineering 2021 in one pic\n",
      "oyju56\n",
      "DataEngineering Modeling questions\n",
      "1cu0zg1\n",
      "AI in dataengineering\n",
      "17i4cb6\n",
      "/r/dataengineering discussing Snowpipe\n",
      "18e0pb4\n",
      "https://dataengineering.ph/\n",
      "1aj60ic\n",
      "Databricks for non dataengineers\n",
      "18jb2ze\n",
      "The most shared resources from r/dataengineering\n",
      "zebb3o\n",
      "How is your job hunt  for datascience/dataengineer roles ?\n",
      "1ctzzba\n",
      "DataEngineering --&gt; DataOps\n",
      "12kpq9i\n"
     ]
    }
   ],
   "source": [
    "for i in r_json['data']['children']:\n",
    "    print(i['data']['title'])\n",
    "    print(i['data']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in r_json['data']['children']:\n",
    "    \n",
    "    subscsriber_count_list.append(i['data']['subreddit_subscribers'])\n",
    "    created_utc_list.append(i['data']['created'])\n",
    "    is_video_list.append(i['data']['is_video'])\n",
    "    post_score_list.append(i['data']['score'])\n",
    "    over_18_list.append(i['data']['over_18'])\n",
    "    author_list.append(i['data']['author'])\n",
    "    num_of_comments_list.append(i['data']['num_comments'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({\n",
    "    'subscriber_count':subscsriber_count_list,\n",
    "    'created_utc':created_utc_list,\n",
    "    'is_video': is_video_list,\n",
    "    'post_score':post_score_list,\n",
    "    'over_18':over_18_list,\n",
    "    'author':author_list,\n",
    "    'comment_count':num_of_comments_list\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subscriber_count</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>is_video</th>\n",
       "      <th>post_score</th>\n",
       "      <th>over_18</th>\n",
       "      <th>author</th>\n",
       "      <th>comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185653</td>\n",
       "      <td>1.628175e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>609</td>\n",
       "      <td>False</td>\n",
       "      <td>Legitimate-Cry2837</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185653</td>\n",
       "      <td>1.705641e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>51</td>\n",
       "      <td>False</td>\n",
       "      <td>gotchabiash</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>185653</td>\n",
       "      <td>1.715938e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>ut0mt8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185653</td>\n",
       "      <td>1.698461e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>RogerRockzz</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10725</td>\n",
       "      <td>1.702081e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>fhoffa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>706</td>\n",
       "      <td>1.707101e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>saintmichel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>185653</td>\n",
       "      <td>1.702677e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>SuperLucas2000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>185653</td>\n",
       "      <td>1.670345e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>177</td>\n",
       "      <td>False</td>\n",
       "      <td>flpezet</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>663855</td>\n",
       "      <td>1.715933e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>Left_Tip_7300</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>185653</td>\n",
       "      <td>1.681393e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Striking_Athlete5685</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subscriber_count   created_utc  is_video  post_score  over_18  \\\n",
       "0            185653  1.628175e+09     False         609    False   \n",
       "1            185653  1.705641e+09     False          51    False   \n",
       "2            185653  1.715938e+09     False           7    False   \n",
       "3            185653  1.698461e+09     False           2    False   \n",
       "4             10725  1.702081e+09     False           2    False   \n",
       "5               706  1.707101e+09     False           5    False   \n",
       "6            185653  1.702677e+09     False           4    False   \n",
       "7            185653  1.670345e+09     False         177    False   \n",
       "8            663855  1.715933e+09     False           2    False   \n",
       "9            185653  1.681393e+09     False           1    False   \n",
       "\n",
       "                 author  comment_count  \n",
       "0    Legitimate-Cry2837             53  \n",
       "1           gotchabiash             74  \n",
       "2                ut0mt8              7  \n",
       "3           RogerRockzz             11  \n",
       "4                fhoffa              0  \n",
       "5           saintmichel              0  \n",
       "6        SuperLucas2000              6  \n",
       "7               flpezet             22  \n",
       "8         Left_Tip_7300              2  \n",
       "9  Striking_Athlete5685              8  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2021-08-05 14:46:15\n",
       "1   2024-01-19 05:04:06\n",
       "2   2024-05-17 09:26:17\n",
       "3   2023-10-28 02:48:02\n",
       "4   2023-12-09 00:13:32\n",
       "5   2024-02-05 02:46:32\n",
       "6   2023-12-15 21:41:57\n",
       "7   2022-12-06 16:38:45\n",
       "8   2024-05-17 08:11:01\n",
       "9   2023-04-13 13:44:43\n",
       "Name: created_utc, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(df['created_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_data(post_df: pd.DataFrame):\n",
    "    post_df['created_utc'] = pd.to_datetime(post_df['created_utc'], unit='s')\n",
    "    post_df['over_18'] = np.where((post_df['over_18'] == True), True, False)\n",
    "    post_df['author'] = post_df['author'].astype(str)\n",
    "    edited_mode = post_df['edited'].mode()\n",
    "    post_df['edited'] = np.where(post_df['edited'].isin([True, False]),\n",
    "                                 post_df['edited'], edited_mode).astype(bool)\n",
    "    post_df['num_comments'] = post_df['num_comments'].astype(int)\n",
    "    post_df['score'] = post_df['score'].astype(int)\n",
    "    post_df['title'] = post_df['title'].astype(str)\n",
    "\n",
    "    return post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind Listing\n",
      "data {'modhash': None, 'dist': 10, 'facets': {}, 'after': 't3_12kpq9i', 'geo_filter': '', 'children': [{'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'dataengineering', 'selftext': '', 'author_fullname': 't2_8wc3ja5x', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'DataEngineering 2021 in one pic', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_oyju56', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.98, 'author_flair_background_color': None, 'ups': 609, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 609, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/n6itUzKOh3oYtUQMsBGOGpwVvlMyUbZeXiCxsPgoovo.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'image', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1628174775.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/pdnuk1r0yjf71.jpg', 'view_count': None, 'archived': True, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://preview.redd.it/pdnuk1r0yjf71.jpg?auto=webp&amp;s=1cf198133dfc62e0a5655de7c550d2aea274e21c', 'width': 640, 'height': 2717}, 'resolutions': [{'url': 'https://preview.redd.it/pdnuk1r0yjf71.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f82b17d894b091fb746bcc1fae88997c1a19f1b', 'width': 108, 'height': 216}, {'url': 'https://preview.redd.it/pdnuk1r0yjf71.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b5552bae4a5ed105d31fe94db4b15429ab188590', 'width': 216, 'height': 432}, {'url': 'https://preview.redd.it/pdnuk1r0yjf71.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=67d48116db51df511b0e99dc62822d67ec0cea8d', 'width': 320, 'height': 640}, {'url': 'https://preview.redd.it/pdnuk1r0yjf71.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8ec4374de2c25383c3fafc48bf4a5267b32f1e6b', 'width': 640, 'height': 1280}], 'variants': {}, 'id': 'L0Na0tk0a9E7q_ragRHveS4dzfkyRO2GaKxFFr57tIM'}], 'enabled': True}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': 'oyju56', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Legitimate-Cry2837', 'discussion_type': None, 'num_comments': 53, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/oyju56/dataengineering_2021_in_one_pic/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://i.redd.it/pdnuk1r0yjf71.jpg', 'subreddit_subscribers': 185653, 'created_utc': 1628174775.0, 'num_crossposts': 2, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'dataengineering', 'selftext': '', 'author_fullname': 't2_4pzy2btji', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How true is this thing of getting “blacklisted” for wrong titles on resumes?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': 140, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_19ab6dx', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.88, 'author_flair_background_color': None, 'ups': 51, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': 140, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': True, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 51, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'https://b.thumbs.redditmedia.com/cuA_e70vkmLGdeTFNaHkMsKadak-ldjPOxUPEQohPpw.jpg', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'image', 'content_categories': None, 'is_self': False, 'subreddit_type': 'public', 'created': 1705640646.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'i.redd.it', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://i.redd.it/h51r0yfcxbdc1.jpeg', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://preview.redd.it/h51r0yfcxbdc1.jpeg?auto=webp&amp;s=09136918e787fe5de8e922a2e1822c1536a7f9c4', 'width': 750, 'height': 1205}, 'resolutions': [{'url': 'https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ced0927fd3b3719458511bc71ff2ccdd641c8a52', 'width': 108, 'height': 173}, {'url': 'https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6a61f119dd5141d0dafd3afde992981047fe7ede', 'width': 216, 'height': 347}, {'url': 'https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f5f55ad22f0cc7f13defcaf55ae9c05f8666af3', 'width': 320, 'height': 514}, {'url': 'https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f2d5ee24b2d9d9d89feea2edd4c800a4603c1d7', 'width': 640, 'height': 1028}], 'variants': {}, 'id': 's-z2epHMrUrmxBEW4R-8PpX4yFQk4_gxuS3qaWaPeqk'}], 'enabled': True}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'mod_note': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'num_reports': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '19ab6dx', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'gotchabiash', 'discussion_type': None, 'num_comments': 74, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/19ab6dx/how_true_is_this_thing_of_getting_blacklisted_for/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://i.redd.it/h51r0yfcxbdc1.jpeg', 'subreddit_subscribers': 185653, 'created_utc': 1705640646.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'dataengineering', 'selftext': 'At works we have an interesting problems which I think is badly solved but I want advices.\\n\\nThe problem is : \\n\\nwe have BIG list of users actions with let say the number of transactions the user done in a specific day, and some other info. (big is potentially billions of lines)\\n\\nthen we want to create list of users with some criterias (let say user that made transactions between data x and y and more than z) and combine them (add/intersect).\\n\\nfor now we store everything in a big Redshift cluster and make SQL query to create export list.  \\nThe cluster is huge (more then 10To / 8 nodes) and this is super slow (queries to create lists but also maintenance tasks). \\n\\nSo I really wonder if any other solutions would be possible. Maybe just storing everything on S3 (or equivalent) and use a big map/reduce (spark?) job would do the job better ?\\n\\nAny hints / ideas appreciated.', 'author_fullname': 't2_lbugjen', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'DataEngineering Modeling questions', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cu0zg1', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1715937977.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;At works we have an interesting problems which I think is badly solved but I want advices.&lt;/p&gt;\\n\\n&lt;p&gt;The problem is : &lt;/p&gt;\\n\\n&lt;p&gt;we have BIG list of users actions with let say the number of transactions the user done in a specific day, and some other info. (big is potentially billions of lines)&lt;/p&gt;\\n\\n&lt;p&gt;then we want to create list of users with some criterias (let say user that made transactions between data x and y and more than z) and combine them (add/intersect).&lt;/p&gt;\\n\\n&lt;p&gt;for now we store everything in a big Redshift cluster and make SQL query to create export list.&lt;br/&gt;\\nThe cluster is huge (more then 10To / 8 nodes) and this is super slow (queries to create lists but also maintenance tasks). &lt;/p&gt;\\n\\n&lt;p&gt;So I really wonder if any other solutions would be possible. Maybe just storing everything on S3 (or equivalent) and use a big map/reduce (spark?) job would do the job better ?&lt;/p&gt;\\n\\n&lt;p&gt;Any hints / ideas appreciated.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cu0zg1', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'ut0mt8', 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cu0zg1/dataengineering_modeling_questions/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cu0zg1/dataengineering_modeling_questions/', 'subreddit_subscribers': 185653, 'created_utc': 1715937977.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'dataengineering', 'selftext': 'I was just very curious, how AI can affect dataengineering. As in which all area in a standard DE project can be replaced by AI.\\nThe reason I am asking this to focus on  developing skills for AI which are DE oriented.', 'author_fullname': 't2_f363j2vr5', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'AI in dataengineering', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_17i4cb6', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1698461282.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I was just very curious, how AI can affect dataengineering. As in which all area in a standard DE project can be replaced by AI.\\nThe reason I am asking this to focus on  developing skills for AI which are DE oriented.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': True, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '17i4cb6', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'RogerRockzz', 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/17i4cb6/ai_in_dataengineering/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/17i4cb6/ai_in_dataengineering/', 'subreddit_subscribers': 185653, 'created_utc': 1698461282.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'snowflake', 'selftext': '', 'author_fullname': 't2_3kxbd', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': '/r/dataengineering discussing Snowpipe', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/snowflake', 'hidden': False, 'pwls': 6, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18e0pb4', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': '', 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'default', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': False, 'mod_note': None, 'created': 1702080812.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'reddit.com', 'allow_live_comments': False, 'selftext_html': None, 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'url_overridden_by_dest': 'https://www.reddit.com/r/dataengineering/comments/18dgo8q/experience_with_snowpipe/', 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': '❄️', 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_318fi', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '18e0pb4', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'fhoffa', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': 'dark', 'permalink': '/r/snowflake/comments/18e0pb4/rdataengineering_discussing_snowpipe/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/18dgo8q/experience_with_snowpipe/', 'subreddit_subscribers': 10725, 'created_utc': 1702080812.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'DataEngineeringPH', 'selftext': 'we now have a home page! ', 'author_fullname': 't2_56myc', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'https://dataengineering.ph/', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/DataEngineeringPH', 'hidden': False, 'pwls': None, 'link_flair_css_class': None, 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1aj60ic', 'quarantine': False, 'link_flair_text_color': 'dark', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 5, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': None, 'can_mod_post': False, 'score': 5, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1707101192.0, 'link_flair_type': 'text', 'wls': None, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.DataEngineeringPH', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;we now have a home page! &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_am2z20', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '', 'id': '1aj60ic', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'saintmichel', 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': None, 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/DataEngineeringPH/comments/1aj60ic/httpsdataengineeringph/', 'parent_whitelist_status': None, 'stickied': False, 'url': 'https://www.reddit.com/r/DataEngineeringPH/comments/1aj60ic/httpsdataengineeringph/', 'subreddit_subscribers': 706, 'created_utc': 1707101192.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'dataengineering', 'selftext': 'Hello, my company is currently storing a ton of data in databricks and i would like to do “stuff” with this data. Like analysis, maybe some graphs, maybe some code to get some specific metrics. Not being a dataengineer (but im a developer) what are some things i can learn in this space to join meetings and not be 100% lost. Is this one of pandas use cases? ', 'author_fullname': 't2_2gjyr66m', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Databricks for non dataengineers', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_18jb2ze', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1702676793.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1702676517.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hello, my company is currently storing a ton of data in databricks and i would like to do “stuff” with this data. Like analysis, maybe some graphs, maybe some code to get some specific metrics. Not being a dataengineer (but im a developer) what are some things i can learn in this space to join meetings and not be 100% lost. Is this one of pandas use cases? &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '18jb2ze', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'SuperLucas2000', 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/18jb2ze/databricks_for_non_dataengineers/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/18jb2ze/databricks_for_non_dataengineers/', 'subreddit_subscribers': 185653, 'created_utc': 1702676517.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'dataengineering', 'selftext': \"Hi, fellow data engineers!\\n\\nI've built a tool to find the best resources shared on r/dataengineering as well as other subreddits.Here is the link: [https://www.gembase.ai/search?q=data+engineering](https://www.gembase.ai/search?q=data+engineering)\\n\\n**Architecture**\\n\\nI gathered all the archive data from Reddit.\\n\\n* Then extracted URLs with Go on a big EC2 machine.\\n* The screenshots and titles were scraped using Python + Playwright hosted on \\\\~1000 ECS tasks.\\n* The recommendations were offline computed with R + Tidyverse.\\n\\nI hope you will enjoy it. Feedback and questions are really appreciated.\", 'author_fullname': 't2_21q5bign', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'The most shared resources from r/dataengineering', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_zebb3o', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 177, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 177, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': True, 'thumbnail': 'self', 'edited': 1682877797.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1670344725.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi, fellow data engineers!&lt;/p&gt;\\n\\n&lt;p&gt;I&amp;#39;ve built a tool to find the best resources shared on &lt;a href=\"/r/dataengineering\"&gt;r/dataengineering&lt;/a&gt; as well as other subreddits.Here is the link: &lt;a href=\"https://www.gembase.ai/search?q=data+engineering\"&gt;https://www.gembase.ai/search?q=data+engineering&lt;/a&gt;&lt;/p&gt;\\n\\n&lt;p&gt;&lt;strong&gt;Architecture&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;p&gt;I gathered all the archive data from Reddit.&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Then extracted URLs with Go on a big EC2 machine.&lt;/li&gt;\\n&lt;li&gt;The screenshots and titles were scraped using Python + Playwright hosted on ~1000 ECS tasks.&lt;/li&gt;\\n&lt;li&gt;The recommendations were offline computed with R + Tidyverse.&lt;/li&gt;\\n&lt;/ul&gt;\\n\\n&lt;p&gt;I hope you will enjoy it. Feedback and questions are really appreciated.&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': True, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': 'zebb3o', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'flpezet', 'discussion_type': None, 'num_comments': 22, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/', 'subreddit_subscribers': 185653, 'created_utc': 1670344725.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'developersIndia', 'selftext': \"Hi everybody . I have been preparing for data science/ data engineer roles for past five months and got only four call backs couldn't clear OA's for three.\\n\\n  \\nHow is your job hunt going on and how do you prepare for DSA , statistics and EDA kind of questions ?\\n\\nWhat is your preparation strategy for acing the OA's and what hurdles are you facing for your YOE in the market ? \", 'author_fullname': 't2_r4eilh96', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How is your job hunt  for datascience/dataengineer roles ?', 'link_flair_richtext': [{'e': 'text', 't': 'Career'}], 'subreddit_name_prefixed': 'r/developersIndia', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1ctzzba', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1715933461.0, 'link_flair_type': 'richtext', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.developersIndia', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi everybody . I have been preparing for data science/ data engineer roles for past five months and got only four call backs couldn&amp;#39;t clear OA&amp;#39;s for three.&lt;/p&gt;\\n\\n&lt;p&gt;How is your job hunt going on and how do you prepare for DSA , statistics and EDA kind of questions ?&lt;/p&gt;\\n\\n&lt;p&gt;What is your preparation strategy for acing the OA&amp;#39;s and what hurdles are you facing for your YOE in the market ? &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': 'confidence', 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '03e7fc80-5628-11ea-9977-0e3f7ea7151f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_2dfnk0', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#5a74cc', 'id': '1ctzzba', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Left_Tip_7300', 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/developersIndia/comments/1ctzzba/how_is_your_job_hunt_for_datasciencedataengineer/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/developersIndia/comments/1ctzzba/how_is_your_job_hunt_for_datasciencedataengineer/', 'subreddit_subscribers': 663855, 'created_utc': 1715933461.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}, {'kind': 't3', 'data': {'approved_at_utc': None, 'subreddit': 'dataengineering', 'selftext': 'Hi all, I just got my position as DataOps from previous job as DataEngineer.   \\n\\n\\nI need some ideas from you about what are daily tasks, responsibilities of DataOps vs DataEngineer and where is the clear cut between the 2 ?  \\n\\n\\nCheers', 'author_fullname': 't2_93s65yqu', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'DataEngineering --&gt; DataOps', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_12kpq9i', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1681393483.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi all, I just got my position as DataOps from previous job as DataEngineer.   &lt;/p&gt;\\n\\n&lt;p&gt;I need some ideas from you about what are daily tasks, responsibilities of DataOps vs DataEngineer and where is the clear cut between the 2 ?  &lt;/p&gt;\\n\\n&lt;p&gt;Cheers&lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': True, 'no_follow': True, 'is_crosspostable': True, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '12kpq9i', 'is_robot_indexable': True, 'report_reasons': None, 'author': 'Striking_Athlete5685', 'discussion_type': None, 'num_comments': 8, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/12kpq9i/dataengineering_dataops/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/12kpq9i/dataengineering_dataops/', 'subreddit_subscribers': 185653, 'created_utc': 1681393483.0, 'num_crossposts': 0, 'media': None, 'is_video': False}}], 'before': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('_content', b'{\"kind\": \"Listing\", \"data\": {\"modhash\": null, \"dist\": 10, \"facets\": {}, \"after\": \"t3_12kpq9i\", \"geo_filter\": \"\", \"children\": [{\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"\", \"author_fullname\": \"t2_8wc3ja5x\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"DataEngineering 2021 in one pic\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": 140, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_oyju56\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 0.98, \"author_flair_background_color\": null, \"ups\": 609, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": 140, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": true, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Career\", \"can_mod_post\": false, \"score\": 609, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"https://b.thumbs.redditmedia.com/n6itUzKOh3oYtUQMsBGOGpwVvlMyUbZeXiCxsPgoovo.jpg\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"post_hint\": \"image\", \"content_categories\": null, \"is_self\": false, \"subreddit_type\": \"public\", \"created\": 1628174775.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"i.redd.it\", \"allow_live_comments\": false, \"selftext_html\": null, \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"url_overridden_by_dest\": \"https://i.redd.it/pdnuk1r0yjf71.jpg\", \"view_count\": null, \"archived\": true, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"preview\": {\"images\": [{\"source\": {\"url\": \"https://preview.redd.it/pdnuk1r0yjf71.jpg?auto=webp&amp;s=1cf198133dfc62e0a5655de7c550d2aea274e21c\", \"width\": 640, \"height\": 2717}, \"resolutions\": [{\"url\": \"https://preview.redd.it/pdnuk1r0yjf71.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f82b17d894b091fb746bcc1fae88997c1a19f1b\", \"width\": 108, \"height\": 216}, {\"url\": \"https://preview.redd.it/pdnuk1r0yjf71.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b5552bae4a5ed105d31fe94db4b15429ab188590\", \"width\": 216, \"height\": 432}, {\"url\": \"https://preview.redd.it/pdnuk1r0yjf71.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=67d48116db51df511b0e99dc62822d67ec0cea8d\", \"width\": 320, \"height\": 640}, {\"url\": \"https://preview.redd.it/pdnuk1r0yjf71.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8ec4374de2c25383c3fafc48bf4a5267b32f1e6b\", \"width\": 640, \"height\": 1280}], \"variants\": {}, \"id\": \"L0Na0tk0a9E7q_ragRHveS4dzfkyRO2GaKxFFr57tIM\"}], \"enabled\": true}, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"069dd614-a7dc-11eb-8e48-0e90f49436a3\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"mod_note\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"num_reports\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#349e48\", \"id\": \"oyju56\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"Legitimate-Cry2837\", \"discussion_type\": null, \"num_comments\": 53, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/oyju56/dataengineering_2021_in_one_pic/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://i.redd.it/pdnuk1r0yjf71.jpg\", \"subreddit_subscribers\": 185653, \"created_utc\": 1628174775.0, \"num_crossposts\": 2, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"\", \"author_fullname\": \"t2_4pzy2btji\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"How true is this thing of getting \\\\u201cblacklisted\\\\u201d for wrong titles on resumes?\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": 140, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_19ab6dx\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 0.88, \"author_flair_background_color\": null, \"ups\": 51, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": 140, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": true, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Discussion\", \"can_mod_post\": false, \"score\": 51, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"https://b.thumbs.redditmedia.com/cuA_e70vkmLGdeTFNaHkMsKadak-ldjPOxUPEQohPpw.jpg\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"post_hint\": \"image\", \"content_categories\": null, \"is_self\": false, \"subreddit_type\": \"public\", \"created\": 1705640646.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"i.redd.it\", \"allow_live_comments\": false, \"selftext_html\": null, \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"url_overridden_by_dest\": \"https://i.redd.it/h51r0yfcxbdc1.jpeg\", \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"preview\": {\"images\": [{\"source\": {\"url\": \"https://preview.redd.it/h51r0yfcxbdc1.jpeg?auto=webp&amp;s=09136918e787fe5de8e922a2e1822c1536a7f9c4\", \"width\": 750, \"height\": 1205}, \"resolutions\": [{\"url\": \"https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ced0927fd3b3719458511bc71ff2ccdd641c8a52\", \"width\": 108, \"height\": 173}, {\"url\": \"https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6a61f119dd5141d0dafd3afde992981047fe7ede\", \"width\": 216, \"height\": 347}, {\"url\": \"https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f5f55ad22f0cc7f13defcaf55ae9c05f8666af3\", \"width\": 320, \"height\": 514}, {\"url\": \"https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f2d5ee24b2d9d9d89feea2edd4c800a4603c1d7\", \"width\": 640, \"height\": 1028}], \"variants\": {}, \"id\": \"s-z2epHMrUrmxBEW4R-8PpX4yFQk4_gxuS3qaWaPeqk\"}], \"enabled\": true}, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"92b74b58-aaca-11eb-b160-0e6181e3773f\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"mod_note\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"num_reports\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#ff4500\", \"id\": \"19ab6dx\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"gotchabiash\", \"discussion_type\": null, \"num_comments\": 74, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/19ab6dx/how_true_is_this_thing_of_getting_blacklisted_for/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://i.redd.it/h51r0yfcxbdc1.jpeg\", \"subreddit_subscribers\": 185653, \"created_utc\": 1705640646.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"At works we have an interesting problems which I think is badly solved but I want advices.\\\\n\\\\nThe problem is : \\\\n\\\\nwe have BIG list of users actions with let say the number of transactions the user done in a specific day, and some other info. (big is potentially billions of lines)\\\\n\\\\nthen we want to create list of users with some criterias (let say user that made transactions between data x and y and more than z) and combine them (add/intersect).\\\\n\\\\nfor now we store everything in a big Redshift cluster and make SQL query to create export list.  \\\\nThe cluster is huge (more then 10To / 8 nodes) and this is super slow (queries to create lists but also maintenance tasks). \\\\n\\\\nSo I really wonder if any other solutions would be possible. Maybe just storing everything on S3 (or equivalent) and use a big map/reduce (spark?) job would do the job better ?\\\\n\\\\nAny hints / ideas appreciated.\", \"author_fullname\": \"t2_lbugjen\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"DataEngineering Modeling questions\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_1cu0zg1\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 0.9, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 7, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Discussion\", \"can_mod_post\": false, \"score\": 7, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1715937977.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.dataengineering\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;At works we have an interesting problems which I think is badly solved but I want advices.&lt;/p&gt;\\\\n\\\\n&lt;p&gt;The problem is : &lt;/p&gt;\\\\n\\\\n&lt;p&gt;we have BIG list of users actions with let say the number of transactions the user done in a specific day, and some other info. (big is potentially billions of lines)&lt;/p&gt;\\\\n\\\\n&lt;p&gt;then we want to create list of users with some criterias (let say user that made transactions between data x and y and more than z) and combine them (add/intersect).&lt;/p&gt;\\\\n\\\\n&lt;p&gt;for now we store everything in a big Redshift cluster and make SQL query to create export list.&lt;br/&gt;\\\\nThe cluster is huge (more then 10To / 8 nodes) and this is super slow (queries to create lists but also maintenance tasks). &lt;/p&gt;\\\\n\\\\n&lt;p&gt;So I really wonder if any other solutions would be possible. Maybe just storing everything on S3 (or equivalent) and use a big map/reduce (spark?) job would do the job better ?&lt;/p&gt;\\\\n\\\\n&lt;p&gt;Any hints / ideas appreciated.&lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"92b74b58-aaca-11eb-b160-0e6181e3773f\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#ff4500\", \"id\": \"1cu0zg1\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"ut0mt8\", \"discussion_type\": null, \"num_comments\": 7, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/1cu0zg1/dataengineering_modeling_questions/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/1cu0zg1/dataengineering_modeling_questions/\", \"subreddit_subscribers\": 185653, \"created_utc\": 1715937977.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"I was just very curious, how AI can affect dataengineering. As in which all area in a standard DE project can be replaced by AI.\\\\nThe reason I am asking this to focus on  developing skills for AI which are DE oriented.\", \"author_fullname\": \"t2_f363j2vr5\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"AI in dataengineering\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_17i4cb6\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 0.67, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 2, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Discussion\", \"can_mod_post\": false, \"score\": 2, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1698461282.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.dataengineering\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;I was just very curious, how AI can affect dataengineering. As in which all area in a standard DE project can be replaced by AI.\\\\nThe reason I am asking this to focus on  developing skills for AI which are DE oriented.&lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": true, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"92b74b58-aaca-11eb-b160-0e6181e3773f\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#ff4500\", \"id\": \"17i4cb6\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"RogerRockzz\", \"discussion_type\": null, \"num_comments\": 11, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/17i4cb6/ai_in_dataengineering/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/17i4cb6/ai_in_dataengineering/\", \"subreddit_subscribers\": 185653, \"created_utc\": 1698461282.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"snowflake\", \"selftext\": \"\", \"author_fullname\": \"t2_3kxbd\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"/r/dataengineering discussing Snowpipe\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/snowflake\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": null, \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_18e0pb4\", \"quarantine\": false, \"link_flair_text_color\": \"dark\", \"upvote_ratio\": 1.0, \"author_flair_background_color\": \"\", \"subreddit_type\": \"public\", \"ups\": 2, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": null, \"can_mod_post\": false, \"score\": 2, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"default\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": false, \"mod_note\": null, \"created\": 1702080812.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"reddit.com\", \"allow_live_comments\": false, \"selftext_html\": null, \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"url_overridden_by_dest\": \"https://www.reddit.com/r/dataengineering/comments/18dgo8q/experience_with_snowpipe/\", \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": \"\\\\u2744\\\\ufe0f\", \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_318fi\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"\", \"id\": \"18e0pb4\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"fhoffa\", \"discussion_type\": null, \"num_comments\": 0, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": \"dark\", \"permalink\": \"/r/snowflake/comments/18e0pb4/rdataengineering_discussing_snowpipe/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/18dgo8q/experience_with_snowpipe/\", \"subreddit_subscribers\": 10725, \"created_utc\": 1702080812.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"DataEngineeringPH\", \"selftext\": \"we now have a home page! \", \"author_fullname\": \"t2_56myc\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"https://dataengineering.ph/\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/DataEngineeringPH\", \"hidden\": false, \"pwls\": null, \"link_flair_css_class\": null, \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_1aj60ic\", \"quarantine\": false, \"link_flair_text_color\": \"dark\", \"upvote_ratio\": 1.0, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 5, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": null, \"can_mod_post\": false, \"score\": 5, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1707101192.0, \"link_flair_type\": \"text\", \"wls\": null, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.DataEngineeringPH\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;we now have a home page! &lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_am2z20\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"\", \"id\": \"1aj60ic\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"saintmichel\", \"discussion_type\": null, \"num_comments\": 0, \"send_replies\": true, \"whitelist_status\": null, \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/DataEngineeringPH/comments/1aj60ic/httpsdataengineeringph/\", \"parent_whitelist_status\": null, \"stickied\": false, \"url\": \"https://www.reddit.com/r/DataEngineeringPH/comments/1aj60ic/httpsdataengineeringph/\", \"subreddit_subscribers\": 706, \"created_utc\": 1707101192.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"Hello, my company is currently storing a ton of data in databricks and i would like to do \\\\u201cstuff\\\\u201d with this data. Like analysis, maybe some graphs, maybe some code to get some specific metrics. Not being a dataengineer (but im a developer) what are some things i can learn in this space to join meetings and not be 100% lost. Is this one of pandas use cases? \", \"author_fullname\": \"t2_2gjyr66m\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"Databricks for non dataengineers\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_18jb2ze\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 1.0, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 4, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Help\", \"can_mod_post\": false, \"score\": 4, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": 1702676793.0, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1702676517.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.dataengineering\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;Hello, my company is currently storing a ton of data in databricks and i would like to do \\\\u201cstuff\\\\u201d with this data. Like analysis, maybe some graphs, maybe some code to get some specific metrics. Not being a dataengineer (but im a developer) what are some things i can learn in this space to join meetings and not be 100% lost. Is this one of pandas use cases? &lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#ea0027\", \"id\": \"18jb2ze\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"SuperLucas2000\", \"discussion_type\": null, \"num_comments\": 6, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/18jb2ze/databricks_for_non_dataengineers/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/18jb2ze/databricks_for_non_dataengineers/\", \"subreddit_subscribers\": 185653, \"created_utc\": 1702676517.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"Hi, fellow data engineers!\\\\n\\\\nI\\'ve built a tool to find the best resources shared on r/dataengineering as well as other subreddits.Here is the link: [https://www.gembase.ai/search?q=data+engineering](https://www.gembase.ai/search?q=data+engineering)\\\\n\\\\n**Architecture**\\\\n\\\\nI gathered all the archive data from Reddit.\\\\n\\\\n* Then extracted URLs with Go on a big EC2 machine.\\\\n* The screenshots and titles were scraped using Python + Playwright hosted on \\\\\\\\~1000 ECS tasks.\\\\n* The recommendations were offline computed with R + Tidyverse.\\\\n\\\\nI hope you will enjoy it. Feedback and questions are really appreciated.\", \"author_fullname\": \"t2_21q5bign\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"The most shared resources from r/dataengineering\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_zebb3o\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 1.0, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 177, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Blog\", \"can_mod_post\": false, \"score\": 177, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": true, \"thumbnail\": \"self\", \"edited\": 1682877797.0, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1670344725.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.dataengineering\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;Hi, fellow data engineers!&lt;/p&gt;\\\\n\\\\n&lt;p&gt;I&amp;#39;ve built a tool to find the best resources shared on &lt;a href=\\\\\"/r/dataengineering\\\\\"&gt;r/dataengineering&lt;/a&gt; as well as other subreddits.Here is the link: &lt;a href=\\\\\"https://www.gembase.ai/search?q=data+engineering\\\\\"&gt;https://www.gembase.ai/search?q=data+engineering&lt;/a&gt;&lt;/p&gt;\\\\n\\\\n&lt;p&gt;&lt;strong&gt;Architecture&lt;/strong&gt;&lt;/p&gt;\\\\n\\\\n&lt;p&gt;I gathered all the archive data from Reddit.&lt;/p&gt;\\\\n\\\\n&lt;ul&gt;\\\\n&lt;li&gt;Then extracted URLs with Go on a big EC2 machine.&lt;/li&gt;\\\\n&lt;li&gt;The screenshots and titles were scraped using Python + Playwright hosted on ~1000 ECS tasks.&lt;/li&gt;\\\\n&lt;li&gt;The recommendations were offline computed with R + Tidyverse.&lt;/li&gt;\\\\n&lt;/ul&gt;\\\\n\\\\n&lt;p&gt;I hope you will enjoy it. Feedback and questions are really appreciated.&lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": true, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"eb739554-a7db-11eb-95d7-0ec0f8f30313\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#0079d3\", \"id\": \"zebb3o\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"flpezet\", \"discussion_type\": null, \"num_comments\": 22, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/\", \"subreddit_subscribers\": 185653, \"created_utc\": 1670344725.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"developersIndia\", \"selftext\": \"Hi everybody . I have been preparing for data science/ data engineer roles for past five months and got only four call backs couldn\\'t clear OA\\'s for three.\\\\n\\\\n  \\\\nHow is your job hunt going on and how do you prepare for DSA , statistics and EDA kind of questions ?\\\\n\\\\nWhat is your preparation strategy for acing the OA\\'s and what hurdles are you facing for your YOE in the market ? \", \"author_fullname\": \"t2_r4eilh96\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"How is your job hunt  for datascience/dataengineer roles ?\", \"link_flair_richtext\": [{\"e\": \"text\", \"t\": \"Career\"}], \"subreddit_name_prefixed\": \"r/developersIndia\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_1ctzzba\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 1.0, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 2, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Career\", \"can_mod_post\": false, \"score\": 2, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1715933461.0, \"link_flair_type\": \"richtext\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.developersIndia\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;Hi everybody . I have been preparing for data science/ data engineer roles for past five months and got only four call backs couldn&amp;#39;t clear OA&amp;#39;s for three.&lt;/p&gt;\\\\n\\\\n&lt;p&gt;How is your job hunt going on and how do you prepare for DSA , statistics and EDA kind of questions ?&lt;/p&gt;\\\\n\\\\n&lt;p&gt;What is your preparation strategy for acing the OA&amp;#39;s and what hurdles are you facing for your YOE in the market ? &lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": \"confidence\", \"banned_at_utc\": null, \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"03e7fc80-5628-11ea-9977-0e3f7ea7151f\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_2dfnk0\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#5a74cc\", \"id\": \"1ctzzba\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"Left_Tip_7300\", \"discussion_type\": null, \"num_comments\": 2, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/developersIndia/comments/1ctzzba/how_is_your_job_hunt_for_datasciencedataengineer/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/developersIndia/comments/1ctzzba/how_is_your_job_hunt_for_datasciencedataengineer/\", \"subreddit_subscribers\": 663855, \"created_utc\": 1715933461.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"Hi all, I just got my position as DataOps from previous job as DataEngineer.   \\\\n\\\\n\\\\nI need some ideas from you about what are daily tasks, responsibilities of DataOps vs DataEngineer and where is the clear cut between the 2 ?  \\\\n\\\\n\\\\nCheers\", \"author_fullname\": \"t2_93s65yqu\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"DataEngineering --&gt; DataOps\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_12kpq9i\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 0.67, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 1, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Career\", \"can_mod_post\": false, \"score\": 1, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1681393483.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.dataengineering\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;Hi all, I just got my position as DataOps from previous job as DataEngineer.   &lt;/p&gt;\\\\n\\\\n&lt;p&gt;I need some ideas from you about what are daily tasks, responsibilities of DataOps vs DataEngineer and where is the clear cut between the 2 ?  &lt;/p&gt;\\\\n\\\\n&lt;p&gt;Cheers&lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": true, \"no_follow\": true, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"069dd614-a7dc-11eb-8e48-0e90f49436a3\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#349e48\", \"id\": \"12kpq9i\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"Striking_Athlete5685\", \"discussion_type\": null, \"num_comments\": 8, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/12kpq9i/dataengineering_dataops/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/12kpq9i/dataengineering_dataops/\", \"subreddit_subscribers\": 185653, \"created_utc\": 1681393483.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}], \"before\": null}}'), ('_content_consumed', True), ('_next', None), ('status_code', 200), ('headers', {'Connection': 'keep-alive', 'Content-Length': '5691', 'x-ua-compatible': 'IE=edge', 'content-type': 'application/json; charset=UTF-8', 'expires': '-1', 'cache-control': 'private, s-maxage=0, max-age=0, must-revalidate, no-store', 'x-ratelimit-remaining': '596.0', 'x-ratelimit-used': '4', 'x-ratelimit-reset': '74', 'content-encoding': 'gzip', 'Accept-Ranges': 'bytes', 'Date': 'Fri, 24 May 2024 21:58:47 GMT', 'Via': '1.1 varnish', 'Vary': 'accept-encoding', 'Strict-Transport-Security': 'max-age=31536000; includeSubdomains', 'X-Content-Type-Options': 'nosniff', 'X-Frame-Options': 'SAMEORIGIN', 'X-XSS-Protection': '1; mode=block', 'Set-Cookie': 'loid=0000000000vmtup5yn.2.1674246553000.Z0FBQUFBQm1VUTJYTG5hVkFBeXk4eGpKbThVV2w5VEozTUdRY1YxcmpkMUk5TXhHNFh0alFnTk13RWlDN3hlbXJJZHk3Z2kwRGxuSDNfWVA3U2RGSWNOYVJ0aVpEcy0zb0lEczc1bHBLQVlDdlZ2M0gycEhpOXpMdU5kWEJvRHRYOXZJZEw4VzhTaXY; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sun, 24-May-2026 21:58:47 GMT; secure; SameSite=None; Secure, session_tracker=errjaeeqfproqearqb.0.1716587926949.Z0FBQUFBQm1VUTJYZXJ1T3FTYkE5OXJOOEpsTU0yaUY1YjFzU0h5SXFUQ3lLdnRpNXF4Y0pNOVZCc0RBX0RnWlB2MVNsVzFCUDNCZ1lvMDBYd2lHZWVnNWlmMkR5OFJ1T0FIMTh2YWNTZmxRMktIdlZjVVlGSy03ODNaeWcxN2EwZ3Fib2k4em1YMW0; Domain=reddit.com; Max-Age=7199; Path=/; expires=Fri, 24-May-2024 23:58:47 GMT; secure; SameSite=None; Secure, csv=2; Max-Age=63072000; Domain=.reddit.com; Path=/; Secure; SameSite=None, edgebucket=VFeOSIs9ua7oAbmyKt; Domain=reddit.com; Max-Age=63071999; Path=/;  secure', 'Server': 'snooserv', 'Report-To': '{\"group\": \"w3-reporting-nel\", \"max_age\": 14400, \"include_subdomains\": true,  \"endpoints\": [{ \"url\": \"https://w3-reporting-nel.reddit.com/reports\" }]}, {\"group\": \"w3-reporting\", \"max_age\": 14400, \"include_subdomains\": true, \"endpoints\": [{ \"url\": \"https://w3-reporting.reddit.com/reports\" }]}, {\"group\": \"w3-reporting-csp\", \"max_age\": 14400, \"include_subdomains\": true, \"endpoints\": [{ \"url\": \"https://w3-reporting-csp.reddit.com/reports\" }]}', 'NEL': '{\"report_to\": \"w3-reporting-nel\", \"max_age\": 14400, \"include_subdomains\": false, \"success_fraction\": 1.0, \"failure_fraction\": 1.0}'}), ('raw', <urllib3.response.HTTPResponse object at 0x000001CAF6CAD310>), ('url', 'https://oauth.reddit.com/r/all/search.json?q=dataengineering&limit=10'), ('encoding', 'UTF-8'), ('history', []), ('reason', 'OK'), ('cookies', <RequestsCookieJar[Cookie(version=0, name='csv', value='2', port=None, port_specified=False, domain='.reddit.com', domain_specified=True, domain_initial_dot=True, path='/', path_specified=True, secure=True, expires=1779659924, discard=False, comment=None, comment_url=None, rest={'SameSite': 'None'}, rfc2109=False), Cookie(version=0, name='edgebucket', value='VFeOSIs9ua7oAbmyKt', port=None, port_specified=False, domain='.reddit.com', domain_specified=True, domain_initial_dot=False, path='/', path_specified=True, secure=True, expires=1779659923, discard=False, comment=None, comment_url=None, rest={}, rfc2109=False), Cookie(version=0, name='loid', value='0000000000vmtup5yn.2.1674246553000.Z0FBQUFBQm1VUTJYTG5hVkFBeXk4eGpKbThVV2w5VEozTUdRY1YxcmpkMUk5TXhHNFh0alFnTk13RWlDN3hlbXJJZHk3Z2kwRGxuSDNfWVA3U2RGSWNOYVJ0aVpEcy0zb0lEczc1bHBLQVlDdlZ2M0gycEhpOXpMdU5kWEJvRHRYOXZJZEw4VzhTaXY', port=None, port_specified=False, domain='.reddit.com', domain_specified=True, domain_initial_dot=False, path='/', path_specified=True, secure=True, expires=1779659923, discard=False, comment=None, comment_url=None, rest={'SameSite': 'None'}, rfc2109=False), Cookie(version=0, name='session_tracker', value='errjaeeqfproqearqb.0.1716587926949.Z0FBQUFBQm1VUTJYZXJ1T3FTYkE5OXJOOEpsTU0yaUY1YjFzU0h5SXFUQ3lLdnRpNXF4Y0pNOVZCc0RBX0RnWlB2MVNsVzFCUDNCZ1lvMDBYd2lHZWVnNWlmMkR5OFJ1T0FIMTh2YWNTZmxRMktIdlZjVVlGSy03ODNaeWcxN2EwZ3Fib2k4em1YMW0', port=None, port_specified=False, domain='.reddit.com', domain_specified=True, domain_initial_dot=False, path='/', path_specified=True, secure=True, expires=1716595123, discard=False, comment=None, comment_url=None, rest={'SameSite': 'None'}, rfc2109=False)]>), ('elapsed', datetime.timedelta(microseconds=275111)), ('request', <PreparedRequest [GET]>), ('connection', <requests.adapters.HTTPAdapter object at 0x000001CAF6CDCBE0>)])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_content b'{\"kind\": \"Listing\", \"data\": {\"modhash\": null, \"dist\": 10, \"facets\": {}, \"after\": \"t3_12kpq9i\", \"geo_filter\": \"\", \"children\": [{\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"\", \"author_fullname\": \"t2_8wc3ja5x\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"DataEngineering 2021 in one pic\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": 140, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_oyju56\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 0.98, \"author_flair_background_color\": null, \"ups\": 609, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": 140, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": true, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Career\", \"can_mod_post\": false, \"score\": 609, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"https://b.thumbs.redditmedia.com/n6itUzKOh3oYtUQMsBGOGpwVvlMyUbZeXiCxsPgoovo.jpg\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"post_hint\": \"image\", \"content_categories\": null, \"is_self\": false, \"subreddit_type\": \"public\", \"created\": 1628174775.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"i.redd.it\", \"allow_live_comments\": false, \"selftext_html\": null, \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"url_overridden_by_dest\": \"https://i.redd.it/pdnuk1r0yjf71.jpg\", \"view_count\": null, \"archived\": true, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"preview\": {\"images\": [{\"source\": {\"url\": \"https://preview.redd.it/pdnuk1r0yjf71.jpg?auto=webp&amp;s=1cf198133dfc62e0a5655de7c550d2aea274e21c\", \"width\": 640, \"height\": 2717}, \"resolutions\": [{\"url\": \"https://preview.redd.it/pdnuk1r0yjf71.jpg?width=108&amp;crop=smart&amp;auto=webp&amp;s=0f82b17d894b091fb746bcc1fae88997c1a19f1b\", \"width\": 108, \"height\": 216}, {\"url\": \"https://preview.redd.it/pdnuk1r0yjf71.jpg?width=216&amp;crop=smart&amp;auto=webp&amp;s=b5552bae4a5ed105d31fe94db4b15429ab188590\", \"width\": 216, \"height\": 432}, {\"url\": \"https://preview.redd.it/pdnuk1r0yjf71.jpg?width=320&amp;crop=smart&amp;auto=webp&amp;s=67d48116db51df511b0e99dc62822d67ec0cea8d\", \"width\": 320, \"height\": 640}, {\"url\": \"https://preview.redd.it/pdnuk1r0yjf71.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8ec4374de2c25383c3fafc48bf4a5267b32f1e6b\", \"width\": 640, \"height\": 1280}], \"variants\": {}, \"id\": \"L0Na0tk0a9E7q_ragRHveS4dzfkyRO2GaKxFFr57tIM\"}], \"enabled\": true}, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"069dd614-a7dc-11eb-8e48-0e90f49436a3\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"mod_note\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"num_reports\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#349e48\", \"id\": \"oyju56\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"Legitimate-Cry2837\", \"discussion_type\": null, \"num_comments\": 53, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/oyju56/dataengineering_2021_in_one_pic/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://i.redd.it/pdnuk1r0yjf71.jpg\", \"subreddit_subscribers\": 185653, \"created_utc\": 1628174775.0, \"num_crossposts\": 2, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"\", \"author_fullname\": \"t2_4pzy2btji\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"How true is this thing of getting \\\\u201cblacklisted\\\\u201d for wrong titles on resumes?\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": 140, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_19ab6dx\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 0.88, \"author_flair_background_color\": null, \"ups\": 51, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": 140, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": true, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Discussion\", \"can_mod_post\": false, \"score\": 51, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"https://b.thumbs.redditmedia.com/cuA_e70vkmLGdeTFNaHkMsKadak-ldjPOxUPEQohPpw.jpg\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"post_hint\": \"image\", \"content_categories\": null, \"is_self\": false, \"subreddit_type\": \"public\", \"created\": 1705640646.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"i.redd.it\", \"allow_live_comments\": false, \"selftext_html\": null, \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"url_overridden_by_dest\": \"https://i.redd.it/h51r0yfcxbdc1.jpeg\", \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"preview\": {\"images\": [{\"source\": {\"url\": \"https://preview.redd.it/h51r0yfcxbdc1.jpeg?auto=webp&amp;s=09136918e787fe5de8e922a2e1822c1536a7f9c4\", \"width\": 750, \"height\": 1205}, \"resolutions\": [{\"url\": \"https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=108&amp;crop=smart&amp;auto=webp&amp;s=ced0927fd3b3719458511bc71ff2ccdd641c8a52\", \"width\": 108, \"height\": 173}, {\"url\": \"https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=216&amp;crop=smart&amp;auto=webp&amp;s=6a61f119dd5141d0dafd3afde992981047fe7ede\", \"width\": 216, \"height\": 347}, {\"url\": \"https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=320&amp;crop=smart&amp;auto=webp&amp;s=1f5f55ad22f0cc7f13defcaf55ae9c05f8666af3\", \"width\": 320, \"height\": 514}, {\"url\": \"https://preview.redd.it/h51r0yfcxbdc1.jpeg?width=640&amp;crop=smart&amp;auto=webp&amp;s=0f2d5ee24b2d9d9d89feea2edd4c800a4603c1d7\", \"width\": 640, \"height\": 1028}], \"variants\": {}, \"id\": \"s-z2epHMrUrmxBEW4R-8PpX4yFQk4_gxuS3qaWaPeqk\"}], \"enabled\": true}, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"92b74b58-aaca-11eb-b160-0e6181e3773f\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"mod_note\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"num_reports\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#ff4500\", \"id\": \"19ab6dx\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"gotchabiash\", \"discussion_type\": null, \"num_comments\": 74, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/19ab6dx/how_true_is_this_thing_of_getting_blacklisted_for/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://i.redd.it/h51r0yfcxbdc1.jpeg\", \"subreddit_subscribers\": 185653, \"created_utc\": 1705640646.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"At works we have an interesting problems which I think is badly solved but I want advices.\\\\n\\\\nThe problem is : \\\\n\\\\nwe have BIG list of users actions with let say the number of transactions the user done in a specific day, and some other info. (big is potentially billions of lines)\\\\n\\\\nthen we want to create list of users with some criterias (let say user that made transactions between data x and y and more than z) and combine them (add/intersect).\\\\n\\\\nfor now we store everything in a big Redshift cluster and make SQL query to create export list.  \\\\nThe cluster is huge (more then 10To / 8 nodes) and this is super slow (queries to create lists but also maintenance tasks). \\\\n\\\\nSo I really wonder if any other solutions would be possible. Maybe just storing everything on S3 (or equivalent) and use a big map/reduce (spark?) job would do the job better ?\\\\n\\\\nAny hints / ideas appreciated.\", \"author_fullname\": \"t2_lbugjen\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"DataEngineering Modeling questions\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_1cu0zg1\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 0.9, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 7, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Discussion\", \"can_mod_post\": false, \"score\": 7, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1715937977.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.dataengineering\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;At works we have an interesting problems which I think is badly solved but I want advices.&lt;/p&gt;\\\\n\\\\n&lt;p&gt;The problem is : &lt;/p&gt;\\\\n\\\\n&lt;p&gt;we have BIG list of users actions with let say the number of transactions the user done in a specific day, and some other info. (big is potentially billions of lines)&lt;/p&gt;\\\\n\\\\n&lt;p&gt;then we want to create list of users with some criterias (let say user that made transactions between data x and y and more than z) and combine them (add/intersect).&lt;/p&gt;\\\\n\\\\n&lt;p&gt;for now we store everything in a big Redshift cluster and make SQL query to create export list.&lt;br/&gt;\\\\nThe cluster is huge (more then 10To / 8 nodes) and this is super slow (queries to create lists but also maintenance tasks). &lt;/p&gt;\\\\n\\\\n&lt;p&gt;So I really wonder if any other solutions would be possible. Maybe just storing everything on S3 (or equivalent) and use a big map/reduce (spark?) job would do the job better ?&lt;/p&gt;\\\\n\\\\n&lt;p&gt;Any hints / ideas appreciated.&lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"92b74b58-aaca-11eb-b160-0e6181e3773f\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#ff4500\", \"id\": \"1cu0zg1\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"ut0mt8\", \"discussion_type\": null, \"num_comments\": 7, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/1cu0zg1/dataengineering_modeling_questions/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/1cu0zg1/dataengineering_modeling_questions/\", \"subreddit_subscribers\": 185653, \"created_utc\": 1715937977.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"I was just very curious, how AI can affect dataengineering. As in which all area in a standard DE project can be replaced by AI.\\\\nThe reason I am asking this to focus on  developing skills for AI which are DE oriented.\", \"author_fullname\": \"t2_f363j2vr5\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"AI in dataengineering\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_17i4cb6\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 0.67, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 2, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Discussion\", \"can_mod_post\": false, \"score\": 2, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1698461282.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.dataengineering\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;I was just very curious, how AI can affect dataengineering. As in which all area in a standard DE project can be replaced by AI.\\\\nThe reason I am asking this to focus on  developing skills for AI which are DE oriented.&lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": true, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"92b74b58-aaca-11eb-b160-0e6181e3773f\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#ff4500\", \"id\": \"17i4cb6\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"RogerRockzz\", \"discussion_type\": null, \"num_comments\": 11, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/17i4cb6/ai_in_dataengineering/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/17i4cb6/ai_in_dataengineering/\", \"subreddit_subscribers\": 185653, \"created_utc\": 1698461282.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"snowflake\", \"selftext\": \"\", \"author_fullname\": \"t2_3kxbd\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"/r/dataengineering discussing Snowpipe\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/snowflake\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": null, \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_18e0pb4\", \"quarantine\": false, \"link_flair_text_color\": \"dark\", \"upvote_ratio\": 1.0, \"author_flair_background_color\": \"\", \"subreddit_type\": \"public\", \"ups\": 2, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": null, \"can_mod_post\": false, \"score\": 2, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"default\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": false, \"mod_note\": null, \"created\": 1702080812.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"reddit.com\", \"allow_live_comments\": false, \"selftext_html\": null, \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"url_overridden_by_dest\": \"https://www.reddit.com/r/dataengineering/comments/18dgo8q/experience_with_snowpipe/\", \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": \"\\\\u2744\\\\ufe0f\", \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_318fi\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"\", \"id\": \"18e0pb4\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"fhoffa\", \"discussion_type\": null, \"num_comments\": 0, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": \"dark\", \"permalink\": \"/r/snowflake/comments/18e0pb4/rdataengineering_discussing_snowpipe/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/18dgo8q/experience_with_snowpipe/\", \"subreddit_subscribers\": 10725, \"created_utc\": 1702080812.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"DataEngineeringPH\", \"selftext\": \"we now have a home page! \", \"author_fullname\": \"t2_56myc\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"https://dataengineering.ph/\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/DataEngineeringPH\", \"hidden\": false, \"pwls\": null, \"link_flair_css_class\": null, \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_1aj60ic\", \"quarantine\": false, \"link_flair_text_color\": \"dark\", \"upvote_ratio\": 1.0, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 5, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": null, \"can_mod_post\": false, \"score\": 5, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1707101192.0, \"link_flair_type\": \"text\", \"wls\": null, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.DataEngineeringPH\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;we now have a home page! &lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_am2z20\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"\", \"id\": \"1aj60ic\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"saintmichel\", \"discussion_type\": null, \"num_comments\": 0, \"send_replies\": true, \"whitelist_status\": null, \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/DataEngineeringPH/comments/1aj60ic/httpsdataengineeringph/\", \"parent_whitelist_status\": null, \"stickied\": false, \"url\": \"https://www.reddit.com/r/DataEngineeringPH/comments/1aj60ic/httpsdataengineeringph/\", \"subreddit_subscribers\": 706, \"created_utc\": 1707101192.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"Hello, my company is currently storing a ton of data in databricks and i would like to do \\\\u201cstuff\\\\u201d with this data. Like analysis, maybe some graphs, maybe some code to get some specific metrics. Not being a dataengineer (but im a developer) what are some things i can learn in this space to join meetings and not be 100% lost. Is this one of pandas use cases? \", \"author_fullname\": \"t2_2gjyr66m\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"Databricks for non dataengineers\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_18jb2ze\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 1.0, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 4, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Help\", \"can_mod_post\": false, \"score\": 4, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": 1702676793.0, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1702676517.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.dataengineering\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;Hello, my company is currently storing a ton of data in databricks and i would like to do \\\\u201cstuff\\\\u201d with this data. Like analysis, maybe some graphs, maybe some code to get some specific metrics. Not being a dataengineer (but im a developer) what are some things i can learn in this space to join meetings and not be 100% lost. Is this one of pandas use cases? &lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#ea0027\", \"id\": \"18jb2ze\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"SuperLucas2000\", \"discussion_type\": null, \"num_comments\": 6, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/18jb2ze/databricks_for_non_dataengineers/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/18jb2ze/databricks_for_non_dataengineers/\", \"subreddit_subscribers\": 185653, \"created_utc\": 1702676517.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"Hi, fellow data engineers!\\\\n\\\\nI\\'ve built a tool to find the best resources shared on r/dataengineering as well as other subreddits.Here is the link: [https://www.gembase.ai/search?q=data+engineering](https://www.gembase.ai/search?q=data+engineering)\\\\n\\\\n**Architecture**\\\\n\\\\nI gathered all the archive data from Reddit.\\\\n\\\\n* Then extracted URLs with Go on a big EC2 machine.\\\\n* The screenshots and titles were scraped using Python + Playwright hosted on \\\\\\\\~1000 ECS tasks.\\\\n* The recommendations were offline computed with R + Tidyverse.\\\\n\\\\nI hope you will enjoy it. Feedback and questions are really appreciated.\", \"author_fullname\": \"t2_21q5bign\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"The most shared resources from r/dataengineering\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_zebb3o\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 1.0, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 177, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Blog\", \"can_mod_post\": false, \"score\": 177, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": true, \"thumbnail\": \"self\", \"edited\": 1682877797.0, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1670344725.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.dataengineering\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;Hi, fellow data engineers!&lt;/p&gt;\\\\n\\\\n&lt;p&gt;I&amp;#39;ve built a tool to find the best resources shared on &lt;a href=\\\\\"/r/dataengineering\\\\\"&gt;r/dataengineering&lt;/a&gt; as well as other subreddits.Here is the link: &lt;a href=\\\\\"https://www.gembase.ai/search?q=data+engineering\\\\\"&gt;https://www.gembase.ai/search?q=data+engineering&lt;/a&gt;&lt;/p&gt;\\\\n\\\\n&lt;p&gt;&lt;strong&gt;Architecture&lt;/strong&gt;&lt;/p&gt;\\\\n\\\\n&lt;p&gt;I gathered all the archive data from Reddit.&lt;/p&gt;\\\\n\\\\n&lt;ul&gt;\\\\n&lt;li&gt;Then extracted URLs with Go on a big EC2 machine.&lt;/li&gt;\\\\n&lt;li&gt;The screenshots and titles were scraped using Python + Playwright hosted on ~1000 ECS tasks.&lt;/li&gt;\\\\n&lt;li&gt;The recommendations were offline computed with R + Tidyverse.&lt;/li&gt;\\\\n&lt;/ul&gt;\\\\n\\\\n&lt;p&gt;I hope you will enjoy it. Feedback and questions are really appreciated.&lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": true, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"eb739554-a7db-11eb-95d7-0ec0f8f30313\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#0079d3\", \"id\": \"zebb3o\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"flpezet\", \"discussion_type\": null, \"num_comments\": 22, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/zebb3o/the_most_shared_resources_from_rdataengineering/\", \"subreddit_subscribers\": 185653, \"created_utc\": 1670344725.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"developersIndia\", \"selftext\": \"Hi everybody . I have been preparing for data science/ data engineer roles for past five months and got only four call backs couldn\\'t clear OA\\'s for three.\\\\n\\\\n  \\\\nHow is your job hunt going on and how do you prepare for DSA , statistics and EDA kind of questions ?\\\\n\\\\nWhat is your preparation strategy for acing the OA\\'s and what hurdles are you facing for your YOE in the market ? \", \"author_fullname\": \"t2_r4eilh96\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"How is your job hunt  for datascience/dataengineer roles ?\", \"link_flair_richtext\": [{\"e\": \"text\", \"t\": \"Career\"}], \"subreddit_name_prefixed\": \"r/developersIndia\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_1ctzzba\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 1.0, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 2, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Career\", \"can_mod_post\": false, \"score\": 2, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1715933461.0, \"link_flair_type\": \"richtext\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.developersIndia\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;Hi everybody . I have been preparing for data science/ data engineer roles for past five months and got only four call backs couldn&amp;#39;t clear OA&amp;#39;s for three.&lt;/p&gt;\\\\n\\\\n&lt;p&gt;How is your job hunt going on and how do you prepare for DSA , statistics and EDA kind of questions ?&lt;/p&gt;\\\\n\\\\n&lt;p&gt;What is your preparation strategy for acing the OA&amp;#39;s and what hurdles are you facing for your YOE in the market ? &lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": \"confidence\", \"banned_at_utc\": null, \"view_count\": null, \"archived\": false, \"no_follow\": false, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"03e7fc80-5628-11ea-9977-0e3f7ea7151f\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_2dfnk0\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#5a74cc\", \"id\": \"1ctzzba\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"Left_Tip_7300\", \"discussion_type\": null, \"num_comments\": 2, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/developersIndia/comments/1ctzzba/how_is_your_job_hunt_for_datasciencedataengineer/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/developersIndia/comments/1ctzzba/how_is_your_job_hunt_for_datasciencedataengineer/\", \"subreddit_subscribers\": 663855, \"created_utc\": 1715933461.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}, {\"kind\": \"t3\", \"data\": {\"approved_at_utc\": null, \"subreddit\": \"dataengineering\", \"selftext\": \"Hi all, I just got my position as DataOps from previous job as DataEngineer.   \\\\n\\\\n\\\\nI need some ideas from you about what are daily tasks, responsibilities of DataOps vs DataEngineer and where is the clear cut between the 2 ?  \\\\n\\\\n\\\\nCheers\", \"author_fullname\": \"t2_93s65yqu\", \"saved\": false, \"mod_reason_title\": null, \"gilded\": 0, \"clicked\": false, \"title\": \"DataEngineering --&gt; DataOps\", \"link_flair_richtext\": [], \"subreddit_name_prefixed\": \"r/dataengineering\", \"hidden\": false, \"pwls\": 6, \"link_flair_css_class\": \"\", \"downs\": 0, \"thumbnail_height\": null, \"top_awarded_type\": null, \"hide_score\": false, \"name\": \"t3_12kpq9i\", \"quarantine\": false, \"link_flair_text_color\": \"light\", \"upvote_ratio\": 0.67, \"author_flair_background_color\": null, \"subreddit_type\": \"public\", \"ups\": 1, \"total_awards_received\": 0, \"media_embed\": {}, \"thumbnail_width\": null, \"author_flair_template_id\": null, \"is_original_content\": false, \"user_reports\": [], \"secure_media\": null, \"is_reddit_media_domain\": false, \"is_meta\": false, \"category\": null, \"secure_media_embed\": {}, \"link_flair_text\": \"Career\", \"can_mod_post\": false, \"score\": 1, \"approved_by\": null, \"is_created_from_ads_ui\": false, \"author_premium\": false, \"thumbnail\": \"self\", \"edited\": false, \"author_flair_css_class\": null, \"author_flair_richtext\": [], \"gildings\": {}, \"content_categories\": null, \"is_self\": true, \"mod_note\": null, \"created\": 1681393483.0, \"link_flair_type\": \"text\", \"wls\": 6, \"removed_by_category\": null, \"banned_by\": null, \"author_flair_type\": \"text\", \"domain\": \"self.dataengineering\", \"allow_live_comments\": false, \"selftext_html\": \"&lt;!-- SC_OFF --&gt;&lt;div class=\\\\\"md\\\\\"&gt;&lt;p&gt;Hi all, I just got my position as DataOps from previous job as DataEngineer.   &lt;/p&gt;\\\\n\\\\n&lt;p&gt;I need some ideas from you about what are daily tasks, responsibilities of DataOps vs DataEngineer and where is the clear cut between the 2 ?  &lt;/p&gt;\\\\n\\\\n&lt;p&gt;Cheers&lt;/p&gt;\\\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;\", \"likes\": null, \"suggested_sort\": null, \"banned_at_utc\": null, \"view_count\": null, \"archived\": true, \"no_follow\": true, \"is_crosspostable\": true, \"pinned\": false, \"over_18\": false, \"all_awardings\": [], \"awarders\": [], \"media_only\": false, \"link_flair_template_id\": \"069dd614-a7dc-11eb-8e48-0e90f49436a3\", \"can_gild\": false, \"spoiler\": false, \"locked\": false, \"author_flair_text\": null, \"treatment_tags\": [], \"visited\": false, \"removed_by\": null, \"num_reports\": null, \"distinguished\": null, \"subreddit_id\": \"t5_36en4\", \"author_is_blocked\": false, \"mod_reason_by\": null, \"removal_reason\": null, \"link_flair_background_color\": \"#349e48\", \"id\": \"12kpq9i\", \"is_robot_indexable\": true, \"report_reasons\": null, \"author\": \"Striking_Athlete5685\", \"discussion_type\": null, \"num_comments\": 8, \"send_replies\": true, \"whitelist_status\": \"all_ads\", \"contest_mode\": false, \"mod_reports\": [], \"author_patreon_flair\": false, \"author_flair_text_color\": null, \"permalink\": \"/r/dataengineering/comments/12kpq9i/dataengineering_dataops/\", \"parent_whitelist_status\": \"all_ads\", \"stickied\": false, \"url\": \"https://www.reddit.com/r/dataengineering/comments/12kpq9i/dataengineering_dataops/\", \"subreddit_subscribers\": 185653, \"created_utc\": 1681393483.0, \"num_crossposts\": 0, \"media\": null, \"is_video\": false}}], \"before\": null}}'\n"
     ]
    }
   ],
   "source": [
    "for key,value in data.items():\n",
    "    print(key,value)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
